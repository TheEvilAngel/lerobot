# Ï€â‚€.â‚… (PI0.5) å®Œæ•´å­¦ä¹ æ€»ç»“

> **ç›®æ ‡**: æ·±å…¥ç†è§£ Ï€â‚€.â‚… çš„æ¶æ„ã€ä¸ Ï€â‚€ çš„å…³é”®åŒºåˆ«ï¼Œä»¥åŠ VLA (Vision-Language-Action) æ¨¡å‹çš„æ ¸å¿ƒæœºåˆ¶

---

## ğŸ“‹ ç›®å½•
1. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
2. [Ï€â‚€.â‚… vs Ï€â‚€ æ ¸å¿ƒå·®å¼‚](#Ï€â‚€â‚…-vs-Ï€â‚€-æ ¸å¿ƒå·®å¼‚)
3. [æ•´ä½“æ¶æ„](#æ•´ä½“æ¶æ„)
4. [å…³é”®å‚æ•°ç†è§£](#å…³é”®å‚æ•°ç†è§£)
5. [æ ¸å¿ƒåˆ›æ–°ï¼šAdaRMS æœºåˆ¶](#æ ¸å¿ƒåˆ›æ–°adarms-æœºåˆ¶)
6. [æ¨ç†æµç¨‹è¯¦è§£](#æ¨ç†æµç¨‹è¯¦è§£)
7. [è®­ç»ƒæµç¨‹è¯¦è§£](#è®­ç»ƒæµç¨‹è¯¦è§£)
8. [æ¨¡å—è¯¦è§£](#æ¨¡å—è¯¦è§£)
9. [ä¸ Ï€â‚€ã€ACTã€DP çš„å¯¹æ¯”](#ä¸-Ï€â‚€actdp-çš„å¯¹æ¯”)
10. [å¸¸è§é¢è¯•é—®é¢˜](#å¸¸è§é¢è¯•é—®é¢˜)

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Ï€â‚€.â‚…ï¼Ÿ

**ä¸€å¥è¯æ€»ç»“**: Ï€â‚€.â‚… æ˜¯ä¸€ä¸ªåŸºäº **Flow Matching** çš„ **Vision-Language-Action (VLA)** æ¨¡å‹ï¼Œé€šè¿‡ **AdaRMS** æœºåˆ¶å®ç°æ—¶é—´æ¡ä»¶è°ƒåˆ¶ï¼Œç”¨äºå¼€æ”¾ä¸–ç•Œçš„æœºå™¨äººæ§åˆ¶ä»»åŠ¡ã€‚

### æ ¸å¿ƒæ€æƒ³å¯¹æ¯”

| å¯¹æ¯”é¡¹ | ACT | Diffusion Policy | Ï€â‚€ | **Ï€â‚€.â‚…** |
|--------|-----|------------------|-----|----------|
| **éª¨å¹²ç½‘ç»œ** | Transformer | ResNet + U-Net | PaliGemma + Gemma | PaliGemma + Gemma |
| **è¾“å…¥æ¨¡æ€** | å›¾åƒ + çŠ¶æ€ | å›¾åƒ + çŠ¶æ€ | å›¾åƒ + è¯­è¨€ + çŠ¶æ€ | **å›¾åƒ + è¯­è¨€ (æ— çŠ¶æ€)** |
| **åŠ¨ä½œç”Ÿæˆ** | VAE æ½œç©ºé—´ | æ‰©æ•£æ¨¡å‹ | Flow Matching | Flow Matching |
| **æ—¶é—´è°ƒåˆ¶** | - | FiLM | Token concatenation | **AdaRMS** |
| **çŠ¶æ€è¾“å…¥** | âœ… éœ€è¦ | âœ… éœ€è¦ | âœ… éœ€è¦ state_proj | **âŒ ç›´æ¥ç¦»æ•£åŒ–** |
| **Tokenizer é•¿åº¦** | - | - | 48 tokens | **200 tokens** |
| **å‚æ•°é‡** | ä¸­ | ä½ | é«˜ (æœ‰ state_proj) | **æ›´ä½** |
| **é›¶æ ·æœ¬æ³›åŒ–** | âŒ | âŒ | âœ… | **âœ…âœ… (æ›´å¼º)** |

---

## ğŸ”¥ Ï€â‚€.â‚… vs Ï€â‚€ æ ¸å¿ƒå·®å¼‚

### 1ï¸âƒ£ **æ—¶é—´æ¡ä»¶æ³¨å…¥æ–¹å¼** (æœ€å…³é”®å·®å¼‚)

#### Ï€â‚€: Token Concatenation
```python
# Ï€â‚€ çš„æ—¶é—´å¤„ç†æ–¹å¼
class PI0Pytorch:
    def __init__(self):
        # éœ€è¦å°† action + time æ‹¼æ¥åæŠ•å½±
        self.action_time_mlp_in = nn.Linear(2 * width, width)  # 2å€å®½åº¦
        self.action_time_mlp_out = nn.Linear(width, width)

    def embed_suffix(self, noisy_actions, timestep):
        time_emb = create_sinusoidal_pos_embedding(timestep, ...)  # [B, 1024]
        action_emb = self.action_in_proj(noisy_actions)           # [B, 50, 1024]

        # å…³é”®: æ‹¼æ¥æ—¶é—´åˆ°æ¯ä¸ªåŠ¨ä½œtoken
        time_emb_expanded = time_emb[:, None, :].expand(-1, 50, -1)  # [B, 50, 1024]
        action_time = torch.cat([action_emb, time_emb_expanded], dim=-1)  # [B, 50, 2048]

        # é€šè¿‡MLPèåˆ
        action_time_emb = self.action_time_mlp_out(
            F.silu(self.action_time_mlp_in(action_time))
        )  # [B, 50, 1024]

        return action_time_emb, None  # æ—  AdaRMS æ¡ä»¶
```

#### Ï€â‚€.â‚…: AdaRMS Conditioning â­
```python
# Ï€â‚€.â‚… çš„æ—¶é—´å¤„ç†æ–¹å¼ (æ ¸å¿ƒåˆ›æ–°)
class PI05Pytorch:
    def __init__(self):
        # åªéœ€è¦å•ç‹¬çš„æ—¶é—´ MLPï¼Œä¸æ‹¼æ¥
        self.time_mlp_in = nn.Linear(width, width)   # å•å€å®½åº¦
        self.time_mlp_out = nn.Linear(width, width)

    def embed_suffix(self, noisy_actions, timestep):
        time_emb = create_sinusoidal_pos_embedding(timestep, ...)  # [B, 1024]
        action_emb = self.action_in_proj(noisy_actions)           # [B, 50, 1024]

        # å…³é”®: æ—¶é—´å•ç‹¬å¤„ç†ï¼Œä¸æ‹¼æ¥
        time_cond = self.time_mlp_out(
            F.silu(self.time_mlp_in(time_emb))
        )  # [B, 1024]

        # åŠ¨ä½œä¿æŒä¸å˜
        action_time_emb = action_emb  # [B, 50, 1024] (æ²¡æœ‰æ‹¼æ¥æ—¶é—´!)
        adarms_cond = time_cond        # [B, 1024] (ä½œä¸º AdaRMS æ¡ä»¶)

        return action_time_emb, adarms_cond
```

**ä¸ºä»€ä¹ˆ Ï€â‚€.â‚… æ›´ä¼˜ï¼Ÿ**
- âœ… **å‚æ•°æ›´å°‘**: ä¸éœ€è¦ 2x å®½åº¦çš„ MLP
- âœ… **æ›´çµæ´»**: æ—¶é—´æ¡ä»¶åœ¨æ¯ä¸€å±‚éƒ½èµ·ä½œç”¨ï¼Œè€Œéåªåœ¨è¾“å…¥å±‚
- âœ… **æ›´å¼ºçš„è°ƒåˆ¶èƒ½åŠ›**: AdaRMS å¯ä»¥åŠ¨æ€è°ƒæ•´æ¯å±‚çš„å½’ä¸€åŒ–å‚æ•°

---

### 2ï¸âƒ£ **AdaRMS ä½¿ç”¨**

```python
# æ¨¡å‹åˆå§‹åŒ–æ—¶çš„å…³é”®å·®å¼‚
# Ï€â‚€
self.paligemma_with_expert = PaliGemmaWithExpertModel(
    use_adarms=[False, False],  # ä¸¤ä¸ªæ¨¡å‹éƒ½ä¸ç”¨ AdaRMS
)

# Ï€â‚€.â‚…
self.paligemma_with_expert = PaliGemmaWithExpertModel(
    use_adarms=[False, True],   # â­ Action expert ä½¿ç”¨ AdaRMS
)
```

**AdaRMS å½±å“çš„ä»£ç è·¯å¾„:**
```python
# åœ¨ Action Expert çš„æ¯ä¸€å±‚
for layer in action_expert_layers:
    # Ï€â‚€: æ ‡å‡† RMSNorm (æ— æ¡ä»¶)
    hidden_states = layer.input_layernorm(hidden_states, cond=None)

    # Ï€â‚€.â‚…: AdaRMS (æ¡ä»¶å½’ä¸€åŒ–)
    hidden_states, gate = layer.input_layernorm(
        hidden_states,
        cond=adarms_cond  # [B, 1024] æ—¶é—´æ¡ä»¶
    )
```

---

### 3ï¸âƒ£ **çŠ¶æ€è¾“å…¥å¤„ç†**

```python
# Ï€â‚€: éœ€è¦ state projection layer
class PI0Pytorch:
    def __init__(self):
        self.state_proj = nn.Linear(max_state_dim, width)  # â­ é¢å¤–çš„å±‚

    def embed_prefix(self, images, img_masks, lang_tokens, lang_masks, state):
        # çŠ¶æ€éœ€è¦é€šè¿‡æŠ•å½±å±‚
        state_emb = self.state_proj(state)  # [B, 32] -> [B, 1024]
        return [..., state_emb]

# Ï€â‚€.â‚…: ç›´æ¥ç¦»æ•£åŒ–çŠ¶æ€ (æ— éœ€ state_proj)
class PI05Pytorch:
    def __init__(self):
        # âŒ æ²¡æœ‰ state_proj å±‚
        pass

    # é…ç½®æ–‡ä»¶ä¸­:
    # discrete_state_input: True  -> çŠ¶æ€ç›´æ¥ä½œä¸º tokens
```

**ä¸ºä»€ä¹ˆå»æ‰ state_projï¼Ÿ**
- Ï€â‚€.â‚… ä½¿ç”¨ **Quantile Normalization**ï¼Œä¹Ÿå°±æ˜¯åˆ†æ¡¶é‡åŒ–äº†ï¼Œå°†è¿ç»­çŠ¶æ€ç¦»æ•£åŒ–
- ç¦»æ•£çŠ¶æ€å¯ä»¥ç›´æ¥ä½œä¸º tokensï¼Œembedåçš„å‘é‡å¯ä»¥ç›´æ¥é€šè¿‡æŸ¥è¡¨æ¥å®Œæˆï¼Œstateç›´æ¥å˜æˆVLMä¸­Lçš„ä¸€éƒ¨åˆ†æ— éœ€é¢å¤–çš„æŠ•å½±å±‚
- å‡å°‘å‚æ•°é‡ï¼Œæå‡æ³›åŒ–èƒ½åŠ›

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
[åŸå§‹è¿ç»­åŠ¨ä½œåºåˆ— aâ‚â€¦H] â”€â–¶â”‚ â‘  å½’ä¸€åŒ– Normalization â”‚â”€â”
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                              â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚ â‘¡ DCT å˜æ¢ (æ—¶åŸŸ â†’ é¢‘åŸŸ) â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ â‘¢ é‡åŒ– Quantizationï¼ˆå››èˆäº”å…¥ï¼‰â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ â‘£ ç¨€ç–çŸ©é˜µ â†’ å±•å¹³ Flatten (ä½é¢‘ä¼˜å…ˆ) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ â‘¤ BPE ç¼–ç ï¼ˆByte Pair Encodingï¼‰             â”‚
                 â”‚   - ç»Ÿè®¡é«˜é¢‘ç¬¦å·å¯¹å¹¶åˆå¹¶                    â”‚
                 â”‚   - ç”Ÿæˆç¦»æ•£ token åºåˆ—                     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ â‘¥ è¾“å‡ºï¼šåŠ¨ä½œ Token åºåˆ— [Tâ‚, Tâ‚‚, â€¦] â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Transformer (Visionâ€‘Languageâ€‘Action æ¨¡å‹è®­ç»ƒ)        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ â‘¦ è§£ç ï¼šBPE è§£ç  â†’ é€†é‡åŒ– â†’ é€† DCT â”‚
               â”‚     â†’ é‡å»ºè¿ç»­åŠ¨ä½œ aÌ‚â‚â€¦H             â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
---

### 4ï¸âƒ£ **Tokenizer é•¿åº¦**

```python
# Ï€â‚€
tokenizer_max_length: int = 48   # çŸ­æŒ‡ä»¤

# Ï€â‚€.â‚…
tokenizer_max_length: int = 200  # â­ æ”¯æŒæ›´é•¿çš„è¯­è¨€æŒ‡ä»¤
```

**å½±å“:**
- Ï€â‚€.â‚… å¯ä»¥å¤„ç†æ›´å¤æ‚çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°
- æ›´é€‚åˆå¼€æ”¾ä¸–ç•Œçš„é›¶æ ·æœ¬æ³›åŒ–

---

### 5ï¸âƒ£ **å½’ä¸€åŒ–ç­–ç•¥**

```python
# Ï€â‚€ (configuration_pi0.py:56-62)
normalization_mapping: dict[str, NormalizationMode] = {
    "STATE": NormalizationMode.MEAN_STD,   # å‡å€¼æ ‡å‡†å·®å½’ä¸€åŒ–
    "ACTION": NormalizationMode.MEAN_STD,
}

# Ï€â‚€.â‚… (configuration_pi05.py:56-62)
normalization_mapping: dict[str, NormalizationMode] = {
    "STATE": NormalizationMode.QUANTILES,  # â­ åˆ†ä½æ•°å½’ä¸€åŒ–
    "ACTION": NormalizationMode.QUANTILES,
}
```

**Quantile Normalization ä¼˜åŠ¿:**
- å¯¹å¼‚å¸¸å€¼æ›´é²æ£’
- æ›´é€‚åˆç¦»æ•£åŒ–å¤„ç†
- è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›æ›´å¼º

---

### ğŸ“Š å·®å¼‚æ€»ç»“è¡¨

| ç‰¹æ€§ | Ï€â‚€ | Ï€â‚€.â‚… | æ”¹è¿›åŸå›  |
|------|-----|------|---------|
| **æ—¶é—´æ¡ä»¶æ–¹å¼** | Token concat (2x MLP) | AdaRMS | å‚æ•°æ›´å°‘ï¼Œè°ƒåˆ¶æ›´å¼º |
| **AdaRMS ä½¿ç”¨** | ä¸ä½¿ç”¨ | Action expert ä½¿ç”¨ | åŠ¨æ€è°ƒæ•´æ¯å±‚å½’ä¸€åŒ– |
| **state_proj** | âœ… æœ‰ | âŒ æ—  | ç¦»æ•£åŒ–çŠ¶æ€ï¼Œå‡å°‘å‚æ•° |
| **Tokenizer é•¿åº¦** | 48 | 200 | æ”¯æŒå¤æ‚æŒ‡ä»¤ |
| **å½’ä¸€åŒ–ç­–ç•¥** | MEAN_STD | QUANTILES | æ›´å¼ºæ³›åŒ– |
| **å‚æ•°é‡** | é«˜ | æ›´ä½ | ç§»é™¤ state_proj ç­‰ |
| **é›¶æ ·æœ¬èƒ½åŠ›** | å¼º | æ›´å¼º | æ¶æ„ä¼˜åŒ– |

---

## ğŸ—ï¸ æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Ï€â‚€.â‚… å®Œæ•´æ¶æ„                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¾“å…¥æ•°æ®æµ:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å›¾åƒ (å¤šç›¸æœº)    â”‚  â”‚ è¯­è¨€æŒ‡ä»¤         â”‚  â”‚ å™ªå£°åŠ¨ä½œ x_t     â”‚
â”‚ (B, n_cam, 3,   â”‚  â”‚ "æ‹¿èµ·çº¢è‰²æ¯å­"   â”‚  â”‚ (B, 50, 7)      â”‚
â”‚  224, 224)      â”‚  â”‚ tokens: [1,...,N]â”‚  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Step 1: Embedding (Prefix å’Œ Suffix)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Prefix (è§‚æµ‹):                 Suffix (åŠ¨ä½œ):              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ SigLIP Vision    â”‚           â”‚ Action Proj      â”‚       â”‚
â”‚  â”‚ Encoder          â”‚           â”‚ (Linear)         â”‚       â”‚
â”‚  â”‚ [B,196,2048]     â”‚           â”‚ [B,50,1024]      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                              â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Gemma Text       â”‚           â”‚ Time MLP â­       â”‚       â”‚
â”‚  â”‚ Embedding        â”‚           â”‚ [B,1024]         â”‚       â”‚
â”‚  â”‚ [B,N,2048]       â”‚           â”‚ (AdaRMS cond)    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚           â”‚                                                 â”‚
â”‚  prefix_embs: [B, 196+N, 2048]   suffix_embs: [B,50,1024]  â”‚
â”‚  prefixä¸éœ€è¦æ—¶é—´æ¡ä»¶              â­ æ—¶é—´ä½œä¸º AdaRMS æ¡ä»¶   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Step 2: Prefix-LM Attention Mask æ„å»º              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  å®Œæ•´åºåˆ—: [å›¾åƒtokens | è¯­è¨€tokens | åŠ¨ä½œtokens]            â”‚
â”‚            [  196      |     N      |    50     ]          â”‚
â”‚                                                             â”‚
â”‚  æ³¨æ„åŠ›çŸ©é˜µ (True = å¯ä»¥ attend):                            â”‚
â”‚       Img0 ... Img195  Lang0 ... LangN  Act0 ... Act49     â”‚
â”‚  Img0   T       T        T        T       F        F       â”‚
â”‚  ...    T       T        T        T       F        F       â”‚
â”‚  Img195 T       T        T        T       F        F       â”‚
â”‚  Lang0  T       T        T        T       F        F       â”‚
â”‚  ...    T       T        T        T       F        F       â”‚
â”‚  LangN  T       T        T        T       F        F       â”‚
â”‚  Act0   T       T        T        T       T        F       â”‚  â† å› æœ
â”‚  Act1   T       T        T        T       T        T       â”‚
â”‚  ...    T       T        T        T       T   ...  T       â”‚
â”‚  Act49  T       T        T        T       T   ...  T       â”‚
â”‚                                                             â”‚
â”‚  â­ å…³é”®: å›¾åƒ+è¯­è¨€å½¼æ­¤å…¨è¿æ¥ï¼ŒåŠ¨ä½œåªèƒ½çœ‹è‡ªå·±å’Œä¹‹å‰çš„åŠ¨ä½œ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Step 3: PaliGemma + Action Expert åŒæ¨¡å‹å¤„ç†          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚          PaliGemma (è§†è§‰+è¯­è¨€)               â”‚           â”‚
â”‚  â”‚  - Gemma 2B Decoder Layers                  â”‚           â”‚
â”‚  â”‚  - å¤„ç† prefix (å›¾åƒ+è¯­è¨€)                   â”‚           â”‚
â”‚  â”‚  - æ—  AdaRMS (use_adarms=False) âŒ           â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                   â”‚                                         â”‚
â”‚                   â–¼                                         â”‚
â”‚         prefix_hidden: [B, 196+N, 2048]                    â”‚
â”‚                   â”‚                                         â”‚
â”‚                   â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚          Action Expert (Gemma 300M) â­       â”‚           â”‚
â”‚  â”‚  - Gemma 300M Decoder Layers                â”‚           â”‚
â”‚  â”‚  - å¤„ç† suffix (åŠ¨ä½œtokens)                  â”‚           â”‚
â”‚  â”‚  - ä½¿ç”¨ AdaRMS (use_adarms=True) âœ…          â”‚           â”‚
â”‚  â”‚                                             â”‚           â”‚
â”‚  â”‚  æ¯ä¸€å±‚:                                     â”‚           â”‚
â”‚  â”‚  for layer in layers:                       â”‚           â”‚
â”‚  â”‚    # â­ AdaRMS å½’ä¸€åŒ– (æ—¶é—´æ¡ä»¶æ³¨å…¥ç‚¹)        â”‚           â”‚
â”‚  â”‚    h, gate = layer.input_layernorm(        â”‚           â”‚
â”‚  â”‚        h,                                   â”‚           â”‚
â”‚  â”‚        cond=adarms_cond  # [B, 1024] æ—¶é—´æ¡ä»¶â”‚           â”‚
â”‚  â”‚    )                                        â”‚           â”‚
â”‚  â”‚    h = layer.self_attn(h, ...)             â”‚           â”‚
â”‚  â”‚    h, gate = layer.post_attention_layernorm(â”‚           â”‚
â”‚  â”‚        h,                                   â”‚           â”‚
â”‚  â”‚        cond=adarms_cond  # å†æ¬¡æ³¨å…¥æ—¶é—´æ¡ä»¶  â”‚           â”‚
â”‚  â”‚    )                                        â”‚           â”‚
â”‚  â”‚    h = layer.mlp(h)                         â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                   â”‚                                         â”‚
â”‚                   â–¼                                         â”‚
â”‚         suffix_hidden: [B, 50, 1024]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Step 4: è¾“å‡ºæŠ•å½± + æŸå¤±è®¡ç®—                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  suffix_hidden [B, 50, 1024]                               â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  action_out_proj (Linear: 1024 -> 7)                       â”‚
â”‚         â”‚                                                   â”‚
â”‚         â–¼                                                   â”‚
â”‚  predicted_velocity: [B, 50, 7]  (é¢„æµ‹é€Ÿåº¦åœº v_Î¸)          â”‚
â”‚                                                             â”‚
â”‚  è®­ç»ƒæŸå¤± (Flow Matching):                                  â”‚
â”‚  target_velocity = noise - actions  (çœŸå®é€Ÿåº¦åœº v = x1-x0)  â”‚
â”‚  loss = MSE(predicted_velocity, target_velocity)           â”‚
â”‚                                                             â”‚
â”‚  æ¨ç†é‡‡æ · (ODE Solver):                                     â”‚
â”‚  for t in [1.0, 0.9, ..., 0.0]:  (10æ­¥)                   â”‚
â”‚      v_t = model(x_t, t, obs)                              â”‚
â”‚      x_t = x_t + v_t * dt  (æ¬§æ‹‰ç§¯åˆ†)                       â”‚
â”‚  return x_0  (å¹²å‡€åŠ¨ä½œ)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¢ å…³é”®å‚æ•°ç†è§£

### æ ¸å¿ƒå‚æ•°

```python
# æ—¶é—´ç»´åº¦å‚æ•°
n_obs_steps = 1          # ä½¿ç”¨å¤šå°‘å¸§å†å²è§‚æµ‹ (Ï€0/Ï€0.5 é€šå¸¸ä¸º 1)
chunk_size = 50          # Flow matching é¢„æµ‹å¤šå°‘æ­¥åŠ¨ä½œ
n_action_steps = 50      # å®é™…æ‰§è¡Œå¤šå°‘æ­¥åŠ¨ä½œ (é€šå¸¸ç­‰äº chunk_size)

# åŠ¨ä½œå’ŒçŠ¶æ€ç»´åº¦
max_action_dim = 32      # åŠ¨ä½œç»´åº¦ä¸Šé™ (çŸ­çš„ä¼š pad åˆ°è¿™ä¸ªé•¿åº¦)
max_state_dim = 32       # çŠ¶æ€ç»´åº¦ä¸Šé™ (Ï€0.5 ä¼šç¦»æ•£åŒ–)

# Flow Matching å‚æ•°
num_inference_steps = 10         # æ¨ç†æ—¶çš„ ODE æ±‚è§£æ­¥æ•°
time_sampling_beta_alpha = 1.5   # Beta åˆ†å¸ƒçš„ Î± (æ§åˆ¶æ—¶é—´é‡‡æ ·åˆ†å¸ƒ)
time_sampling_beta_beta = 1.0    # Beta åˆ†å¸ƒçš„ Î²
min_period = 4e-3               # æ—¶é—´ç¼–ç çš„æœ€å°å‘¨æœŸ
max_period = 4.0                # æ—¶é—´ç¼–ç çš„æœ€å¤§å‘¨æœŸ

# æ¨¡å‹æ¶æ„
paligemma_variant = "gemma_2b"       # è§†è§‰+è¯­è¨€éª¨å¹² (2B å‚æ•°)
action_expert_variant = "gemma_300m" # åŠ¨ä½œä¸“å®¶ (300M å‚æ•°)
tokenizer_max_length = 200           # â­ Ï€0.5 æ”¯æŒæ›´é•¿æŒ‡ä»¤ (Ï€0 æ˜¯ 48)
```

### å‚æ•°å…³ç³»å›¾

```
æ—¶é—´è½´:  t (å½“å‰)   t+1   t+2   ...  t+49
         |          |     |          |
è§‚æµ‹:     o_t        -     -          -
         â”‚
         â””â”€â†’ n_obs_steps=1 (åªç”¨å½“å‰å¸§)

åŠ¨ä½œ:     -         a_1   a_2  ...  a_50
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    chunk_size=50
                    n_action_steps=50
                    (é¢„æµ‹å’Œæ‰§è¡Œé•¿åº¦ç›¸åŒ)
```

---

## ğŸŒŸ æ ¸å¿ƒåˆ›æ–°ï¼šAdaRMS æœºåˆ¶

### ä»€ä¹ˆæ˜¯ AdaRMSï¼Ÿ

**AdaRMS = Adaptive Root Mean Square Normalization**

ä¼ ç»Ÿ RMSNorm çš„å‡çº§ç‰ˆï¼Œå…è®¸é€šè¿‡**æ¡ä»¶ä¿¡æ¯åŠ¨æ€è°ƒæ•´å½’ä¸€åŒ–å‚æ•°**ã€‚

### æ•°å­¦åŸç†

#### æ ‡å‡† RMSNorm (Ï€â‚€ ä½¿ç”¨)
```python
def RMSNorm(x, weight):
    """
    x: [B, T, D] è¾“å…¥ç‰¹å¾
    weight: [D] å¯å­¦ä¹ çš„ç¼©æ”¾å‚æ•°
    """
    rms = sqrt(mean(x^2) + eps)  # [B, T, 1]
    normalized = x / rms          # [B, T, D]
    return weight * normalized    # [B, T, D]
```

#### AdaRMS (Ï€â‚€.â‚… ä½¿ç”¨) â­
```python
def AdaRMS(x, weight, cond):
    """
    x: [B, T, D] è¾“å…¥ç‰¹å¾
    weight: [D] åŸºç¡€ç¼©æ”¾å‚æ•°
    cond: [B, C] æ¡ä»¶ä¿¡æ¯ (æ—¶é—´æ­¥ç¼–ç )
    """
    # 1. æ ‡å‡† RMS å½’ä¸€åŒ–
    rms = sqrt(mean(x^2) + eps)
    normalized = x / rms

    # 2. ä»æ¡ä»¶ç”ŸæˆåŠ¨æ€ç¼©æ”¾å› å­ (scale) å’Œåç§»é‡ (shift)
    # â­ å…³é”®: é€šè¿‡ MLP å­¦ä¹ æ¡ä»¶åˆ°å½’ä¸€åŒ–å‚æ•°çš„æ˜ å°„
    cond_proj = MLP(cond)  # [B, C] -> [B, 2*D]
    scale = 1 + cond_proj[:, :D]    # [B, D] (åŠ æ€§ï¼ŒåŸºå‡†ä¸º 1)
    shift = cond_proj[:, D:]        # [B, D]

    # 3. åº”ç”¨åŠ¨æ€è°ƒåˆ¶
    modulated = scale[:, None, :] * (weight * normalized) + shift[:, None, :]

    return modulated  # [B, T, D]
```

### ä»£ç å®ç°å¯¹æ¯”

#### Ï€â‚€ (æ—  AdaRMS)
```python
# modeling_pi0.py:238-240
class GemmaLayer:
    def forward(self, hidden_states):
        # æ ‡å‡† RMSNormï¼Œæ— æ¡ä»¶
        residual = hidden_states
        hidden_states = self.input_layernorm(hidden_states)  # âŒ æ—  cond
        hidden_states = self.self_attn(hidden_states, ...)
        hidden_states = residual + hidden_states
        return hidden_states
```

#### Ï€â‚€.â‚… (ä½¿ç”¨ AdaRMS) â­
```python
# modeling_pi05.py:238-240
class GemmaLayer:
    def forward(self, hidden_states, adarms_cond):
        # AdaRMSï¼Œæ¡ä»¶æ³¨å…¥
        residual = hidden_states
        hidden_states, gate = self.input_layernorm(
            hidden_states,
            cond=adarms_cond  # â­ [B, 1024] æ—¶é—´æ¡ä»¶
        )
        hidden_states = self.self_attn(hidden_states, ...)
        hidden_states = residual + hidden_states

        # Post-attention ä¹Ÿä½¿ç”¨ AdaRMS
        residual = hidden_states
        hidden_states, gate = self.post_attention_layernorm(
            hidden_states,
            cond=adarms_cond  # â­ å†æ¬¡æ³¨å…¥
        )
        hidden_states = self.mlp(hidden_states)
        hidden_states = residual + hidden_states
        return hidden_states
```

### AdaRMS çš„ä¼˜åŠ¿

**1. æ›´å¼ºçš„æ—¶é—´å»ºæ¨¡èƒ½åŠ›**
```python
# æ—¶é—´æ­¥ t=0.1 (æ—©æœŸ)
scale_early = [1.2, 0.8, ...]  # æ”¾å¤§æŸäº›é€šé“ï¼ŒæŠ‘åˆ¶å…¶ä»–
shift_early = [0.1, -0.2, ...]

# æ—¶é—´æ­¥ t=0.9 (æ™šæœŸ)
scale_late = [0.9, 1.5, ...]   # ä¸åŒçš„è°ƒåˆ¶æ¨¡å¼
shift_late = [-0.3, 0.4, ...]

â†’ ç½‘ç»œå¯ä»¥æ ¹æ®æ—¶é—´æ­¥**åŠ¨æ€è°ƒæ•´ç‰¹å¾åˆ†å¸ƒ**
```

**2. å‡å°‘å‚æ•°é‡**
```
Ï€â‚€ æ–¹å¼: action_dim (7) + time_dim (1024) â†’ 2x MLP â†’ action_dim (7)
         éœ€è¦ 2 * 1024 * 1024 = 2M å‚æ•°

Ï€â‚€.â‚… æ–¹å¼: time_dim (1024) â†’ MLP â†’ time_cond (1024)
          éœ€è¦ 1024 * 1024 = 1M å‚æ•°

èŠ‚çœ: ~50% å‚æ•°
```

**3. æ›´çµæ´»çš„æ¡ä»¶æ³¨å…¥**
- Ï€â‚€: æ—¶é—´ä¿¡æ¯åªåœ¨è¾“å…¥å±‚èåˆï¼Œåç»­å±‚æ— æ³•ç›´æ¥æ„ŸçŸ¥
- Ï€â‚€.â‚…: æ¯ä¸€å±‚éƒ½é€šè¿‡ AdaRMS ç›´æ¥æ„ŸçŸ¥æ—¶é—´ä¿¡æ¯

### å¯è§†åŒ–ç¤ºä¾‹

```python
# å‡è®¾æŸä¸ªé€šé“çš„ç‰¹å¾
feature = [0.5, 0.3, 0.8, ...]  # [B, T, D]

# t=0.1 æ—¶ (æ—©æœŸ, å™ªå£°å¤š)
scale_0.1 = [1.5, 1.5, 1.5, ...]  # æ”¾å¤§æ‰€æœ‰ç‰¹å¾
shift_0.1 = [0.0, 0.0, 0.0, ...]
output_0.1 = 1.5 * feature + 0.0 = [0.75, 0.45, 1.2, ...]

# t=0.9 æ—¶ (æ™šæœŸ, å™ªå£°å°‘)
scale_0.9 = [0.8, 0.8, 0.8, ...]  # ç¼©å°ç‰¹å¾
shift_0.9 = [0.1, 0.1, 0.1, ...]
output_0.9 = 0.8 * feature + 0.1 = [0.5, 0.34, 0.74, ...]

â†’ ä¸åŒæ—¶é—´æ­¥ï¼Œç½‘ç»œå¯¹ç‰¹å¾çš„è°ƒåˆ¶ç­–ç•¥ä¸åŒ
```

---

## ğŸ”„ æ¨ç†æµç¨‹è¯¦è§£

### å®Œæ•´æ¨ç†æµç¨‹ (ä»è§‚æµ‹åˆ°åŠ¨ä½œ)

```python
# ============ æ¨ç†å…¥å£ ============
def select_action(batch):
    """
    è¾“å…¥:
      batch["observation.images"]: [B, 1, n_cam, 3, 224, 224]
      batch["observation.language_tokens"]: [B, 1, N]
      batch["observation.language_attention_mask"]: [B, 1, N]
    è¾“å‡º:
      actions: [B, 50, 7]  # chunk_size=50 çš„åŠ¨ä½œåºåˆ—
    """
    # ============ Step 1: å‡†å¤‡è§‚æµ‹ ============
    # æå–å›¾åƒå’Œè¯­è¨€
    images = batch["observation.images"][:, 0]      # [B, n_cam, 3, 224, 224]
    tokens = batch["observation.language_tokens"][:, 0]  # [B, N]
    masks = batch["observation.language_attention_mask"][:, 0]  # [B, N]

    # ============ Step 2: åˆå§‹åŒ–å™ªå£° ============
    # ä»æ ‡å‡†é«˜æ–¯åˆ†å¸ƒé‡‡æ ·åˆå§‹å™ªå£°
    x_t = torch.randn(B, chunk_size, action_dim)  # [B, 50, 7] ~ N(0, I)

    # ============ Step 3: è¿­ä»£ ODE æ±‚è§£ (Flow Matching) ============
    actions = sample_actions(images, tokens, masks, x_t)

    return actions


# ============ è¯¦ç»†: sample_actions (ODE Solver) ============
def sample_actions(images, tokens, masks, x_init):
    """
    Flow Matching çš„æ¨ç†è¿‡ç¨‹ (Probability Flow ODE)
    """
    # å½“å‰çŠ¶æ€
    x_t = x_init  # [B, 50, 7] åˆå§‹å™ªå£°

    # æ—¶é—´æ­¥è®¾ç½® (ä» 1.0 åˆ° 0.0)
    timesteps = torch.linspace(1.0, 0.0, num_inference_steps + 1)
    # ä¾‹å¦‚: [1.0, 0.9, 0.8, ..., 0.1, 0.0] (11ä¸ªç‚¹ï¼Œ10æ­¥)

    # ============ è¿­ä»£å»å™ª ============
    for i in range(num_inference_steps):
        t_start = timesteps[i]      # ä¾‹å¦‚ 0.9
        t_end = timesteps[i + 1]    # ä¾‹å¦‚ 0.8
        dt = t_end - t_start        # -0.1 (è´Ÿæ•°ï¼Œå› ä¸ºä» 1 åˆ° 0)

        # å½“å‰æ—¶é—´æ­¥
        t = torch.full((B,), t_start, device=x_t.device)  # [B]

        # ============ é¢„æµ‹é€Ÿåº¦åœº v_t ============
        # 1. Embed prefix (å›¾åƒ + è¯­è¨€)
        prefix_embs, prefix_pad_masks, prefix_att_masks = embed_prefix(
            images, img_masks, tokens, masks
        )

        # 2. Embed suffix (åŠ¨ä½œ + æ—¶é—´)
        suffix_embs, suffix_pad_masks, suffix_att_masks, adarms_cond = embed_suffix(
            x_t, t  # â­ x_t ä½œä¸ºè¾“å…¥ï¼Œt ä½œä¸º AdaRMS æ¡ä»¶
        )

        # 3. æ‹¼æ¥æ³¨æ„åŠ› mask
        pad_masks = torch.cat([prefix_pad_masks, suffix_pad_masks], dim=1)
        att_masks = torch.cat([prefix_att_masks, suffix_att_masks], dim=1)
        att_2d_masks = make_att_2d_masks(pad_masks, att_masks)
        att_2d_masks_4d = prepare_attention_masks_4d(att_2d_masks)

        # 4. å‰å‘ä¼ æ’­ (PaliGemma + Action Expert)
        suffix_hidden = paligemma_with_expert(
            prefix_embs,
            suffix_embs,
            attention_mask=att_2d_masks_4d,
            position_ids=position_ids,
            adarms_cond=[None, adarms_cond],  # â­ åªåœ¨ Action Expert ä½¿ç”¨
        )

        # 5. è¾“å‡ºæŠ•å½±
        v_t = action_out_proj(suffix_hidden)  # [B, 50, 7]

        # ============ æ›´æ–° x_t (ODE ç§¯åˆ†) ============
        # Euler æ–¹æ³•: x_{t+dt} = x_t + v_t * dt
        x_t = x_t + v_t * dt

        # å¯é€‰: è£å‰ªåˆ°åˆç†èŒƒå›´
        if clip_sample:
            x_t = torch.clamp(x_t, -1.0, 1.0)

    # ============ è¿”å›æœ€ç»ˆåŠ¨ä½œ ============
    return x_t  # [B, 50, 7]
```

### æ¨ç†æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ¨ç†æµç¨‹ (Inference)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¾“å…¥: è§‚æµ‹ (å›¾åƒ + è¯­è¨€)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. åˆå§‹åŒ–å™ªå£°   â”‚  x_1 ~ N(0, I)  [B, 50, 7]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. ODE æ±‚è§£ (å¾ªç¯ 10 æ¬¡) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â†’ t=1.0: x_1.0 (çº¯å™ªå£°)
         â”‚       â”‚
         â”‚       â–¼
         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   â”‚ embed_prefix(images, tokens)    â”‚
         â”‚   â”‚ embed_suffix(x_t, t) â­          â”‚
         â”‚   â”‚   â†’ adarms_cond = time_mlp(t)   â”‚
         â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚   â”‚ PaliGemma (prefix, no AdaRMS)   â”‚
         â”‚   â”‚ Action Expert (suffix, AdaRMS)â­ â”‚
         â”‚   â”‚   â†’ v_1.0 = model(x_1.0, t=1.0) â”‚
         â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚       â”‚
         â”‚       â–¼
         â”‚   x_0.9 = x_1.0 + v_1.0 * (-0.1)
         â”‚       â”‚
         â”‚       â–¼
         â”œâ”€â†’ t=0.9: x_0.9
         â”‚      ...
         â”‚       â–¼
         â”‚   x_0.8 = x_0.9 + v_0.9 * (-0.1)
         â”‚      ...
         â”‚       â–¼
         â””â”€â†’ t=0.0: x_0.0 (å¹²å‡€åŠ¨ä½œ)
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3. åå½’ä¸€åŒ–     â”‚  åŠ¨ä½œä» [-1, 1] æ˜ å°„å›çœŸå®èŒƒå›´
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    è¾“å‡º: åŠ¨ä½œåºåˆ— [B, 50, 7]
```

### Flow Matching ODE æ•°å­¦åŸç†

```python
"""
Flow Matching çš„æ ¸å¿ƒ ODE:
dx/dt = v_Î¸(x_t, t, obs)

å…¶ä¸­:
- x_t: å½“å‰çŠ¶æ€ (t=1 æ˜¯å™ªå£°, t=0 æ˜¯å¹²å‡€åŠ¨ä½œ)
- v_Î¸: å­¦ä¹ çš„é€Ÿåº¦åœº
- obs: è§‚æµ‹æ¡ä»¶

è®­ç»ƒæ—¶å­¦ä¹ çš„ç›®æ ‡:
v_Î¸(x_t, t, obs) â‰ˆ v_true = x_0 - x_1
                         = actions - noise

æ¨ç†æ—¶æ±‚è§£ ODE:
x_t â†’ x_{t-dt} â†’ ... â†’ x_0
é€šè¿‡ Euler æ–¹æ³•: x_{t-dt} = x_t + v_Î¸(x_t, t) * (-dt)
"""
```

---

## ğŸ“ è®­ç»ƒæµç¨‹è¯¦è§£

### å®Œæ•´è®­ç»ƒæµç¨‹

```python
# ============ è®­ç»ƒä¸€ä¸ª Batch ============
def compute_loss(batch):
    """
    è¾“å…¥:
      batch["observation.images"]: [B, 1, n_cam, 3, 224, 224]
      batch["observation.language_tokens"]: [B, 1, N]
      batch["observation.language_attention_mask"]: [B, 1, N]
      batch["action"]: [B, 50, 7]
    è¾“å‡º:
      loss: scalar
    """
    # ============ Step 1: å‡†å¤‡æ•°æ® ============
    images = batch["observation.images"][:, 0]      # [B, n_cam, 3, 224, 224]
    tokens = batch["observation.language_tokens"][:, 0]  # [B, N]
    masks = batch["observation.language_attention_mask"][:, 0]  # [B, N]
    actions = batch["action"]  # [B, 50, 7] å¹²å‡€åŠ¨ä½œ

    # ============ Step 2: é‡‡æ ·å™ªå£°å’Œæ—¶é—´æ­¥ ============
    # 2.1 é‡‡æ ·å™ªå£°
    noise = torch.randn_like(actions)  # [B, 50, 7] ~ N(0, I)

    # 2.2 é‡‡æ ·æ—¶é—´æ­¥ (ä½¿ç”¨ Beta åˆ†å¸ƒ)
    time = sample_beta(
        alpha=1.5,
        beta=1.0,
        bsize=B,
        device=actions.device
    )  # [B] èŒƒå›´ [0, 1]

    # é€šå¸¸æ—¶é—´åˆ†å¸ƒåå‘ 0.5-1.0 (æ›´å¤šè®­ç»ƒå›°éš¾çš„æ—¶é—´æ­¥)
    time = time * 0.999 + 0.001  # [0.001, 1.0]

    # ============ Step 3: Flow Matching å‰å‘è¿‡ç¨‹ ============
    # çº¿æ€§æ’å€¼: x_t = t * noise + (1-t) * actions
    time_expanded = time[:, None, None]  # [B, 1, 1] ç”¨äºå¹¿æ’­
    x_t = time_expanded * noise + (1 - time_expanded) * actions

    # è®¡ç®—çœŸå®é€Ÿåº¦åœº: v = x_1 - x_0 = noise - actions
    target_velocity = noise - actions  # [B, 50, 7]

    # ============ Step 4: å‰å‘ä¼ æ’­é¢„æµ‹é€Ÿåº¦åœº ============
    predicted_velocity = model.forward(
        images,
        img_masks,
        tokens,
        masks,
        actions=x_t,  # â­ è¾“å…¥å™ªå£°åŠ¨ä½œ
        time=time     # â­ æ—¶é—´æ­¥ä½œä¸º AdaRMS æ¡ä»¶
    )
    # predicted_velocity: [B, 50, 7]

    # ============ Step 5: è®¡ç®—æŸå¤± ============
    loss = F.mse_loss(predicted_velocity, target_velocity)

    return loss


# ============ è¯¦ç»†: model.forward ============
def forward(images, img_masks, tokens, masks, actions, time):
    """
    è®­ç»ƒæ—¶çš„å‰å‘ä¼ æ’­
    """
    # 1. Embed prefix (å›¾åƒ + è¯­è¨€)
    prefix_embs, prefix_pad_masks, prefix_att_masks = embed_prefix(
        images, img_masks, tokens, masks
    )
    # prefix_embs: [B, 196+N, 2048]

    # 2. Embed suffix (å™ªå£°åŠ¨ä½œ + æ—¶é—´)
    suffix_embs, suffix_pad_masks, suffix_att_masks, adarms_cond = embed_suffix(
        actions,  # x_t (å™ªå£°åŠ¨ä½œ)
        time      # [B] æ—¶é—´æ­¥
    )
    # suffix_embs: [B, 50, 1024]
    # adarms_cond: [B, 1024] â­ æ—¶é—´æ¡ä»¶

    # 3. æ„å»ºæ³¨æ„åŠ› mask (Prefix-LM)
    pad_masks = torch.cat([prefix_pad_masks, suffix_pad_masks], dim=1)
    att_masks = torch.cat([prefix_att_masks, suffix_att_masks], dim=1)
    att_2d_masks = make_att_2d_masks(pad_masks, att_masks)
    att_2d_masks_4d = prepare_attention_masks_4d(att_2d_masks)

    # 4. åŒæ¨¡å‹å¤„ç†
    suffix_hidden = paligemma_with_expert(
        prefix_embs,
        suffix_embs,
        attention_mask=att_2d_masks_4d,
        position_ids=position_ids,
        adarms_cond=[None, adarms_cond],  # â­ åªåœ¨ Action Expert ä½¿ç”¨
    )
    # suffix_hidden: [B, 50, 1024]

    # 5. è¾“å‡ºæŠ•å½±
    predicted_velocity = action_out_proj(suffix_hidden)  # [B, 50, 7]

    return predicted_velocity
```

### è®­ç»ƒæµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è®­ç»ƒæµç¨‹ (Training)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¾“å…¥: Batch {è§‚æµ‹, åŠ¨ä½œ}
    â”‚
    â”œâ”€â†’ images: [B, n_cam, 3, 224, 224]
    â”œâ”€â†’ tokens: [B, N]
    â”œâ”€â†’ masks:  [B, N]
    â””â”€â†’ actions: [B, 50, 7] (å¹²å‡€åŠ¨ä½œ)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. é‡‡æ ·å™ªå£°å’Œæ—¶é—´                        â”‚
â”‚                                         â”‚
â”‚  noise = randn([B, 50, 7])  ~ N(0, I)  â”‚
â”‚  time = Beta(1.5, 1.0) ~ [0.001, 1.0]  â”‚
â”‚                                         â”‚
â”‚  æ—¶é—´åˆ†å¸ƒç¤ºä¾‹:                           â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  t âˆˆ [0.5, 1.0] (å¤š) â”‚
â”‚  â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  t âˆˆ [0.0, 0.5] (å°‘) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Flow Matching å‰å‘è¿‡ç¨‹                â”‚
â”‚                                         â”‚
â”‚  çº¿æ€§æ’å€¼:                               â”‚
â”‚  x_t = t * noise + (1-t) * actions     â”‚
â”‚                                         â”‚
â”‚  ç¤ºä¾‹ (t=0.3):                          â”‚
â”‚  x_0.3 = 0.3 * [1,2,3] + 0.7 * [4,5,6] â”‚
â”‚        = [3.1, 4.1, 5.1]               â”‚
â”‚                                         â”‚
â”‚  çœŸå®é€Ÿåº¦åœº:                             â”‚
â”‚  v_true = noise - actions              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. æ¨¡å‹é¢„æµ‹                              â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ embed_prefix(images, tokens) â”‚      â”‚
â”‚  â”‚  â†’ [B, 196+N, 2048]          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚             â”‚                          â”‚
â”‚             â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ embed_suffix(x_t, t) â­       â”‚      â”‚
â”‚  â”‚  â†’ action_emb: [B, 50, 1024] â”‚      â”‚
â”‚  â”‚  â†’ adarms_cond: [B, 1024]    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚             â”‚                          â”‚
â”‚             â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ PaliGemma (prefix)           â”‚      â”‚
â”‚  â”‚ + Action Expert (suffix)â­    â”‚      â”‚
â”‚  â”‚   æ¯å±‚æ³¨å…¥ adarms_cond        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚             â”‚                          â”‚
â”‚             â–¼                          â”‚
â”‚  v_pred = action_out_proj(hidden)     â”‚
â”‚         = [B, 50, 7]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. è®¡ç®—æŸå¤±                              â”‚
â”‚                                         â”‚
â”‚  loss = MSE(v_pred, v_true)            â”‚
â”‚       = MSE(v_pred, noise - actions)   â”‚
â”‚                                         â”‚
â”‚  æ•°å€¼ç¤ºä¾‹:                               â”‚
â”‚  v_pred  = [0.1, 0.2, ...]             â”‚
â”‚  v_true  = [0.15, 0.18, ...]           â”‚
â”‚  loss    = mean((0.05)^2 + (0.02)^2 +..)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. åå‘ä¼ æ’­                              â”‚
â”‚                                         â”‚
â”‚  loss.backward()                        â”‚
â”‚  optimizer.step()                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow Matching vs Diffusion å¯¹æ¯”

```python
"""
Diffusion Policy (æ‰©æ•£):
- å‰å‘: é€æ­¥åŠ å™ªå£° q(x_t | x_0) = N(sqrt(Î±_t)*x_0, (1-Î±_t)*I)
- è®­ç»ƒ: é¢„æµ‹å™ªå£° Îµ
- æ¨ç†: é€æ­¥å»å™ª (DDPM/DDIM)
- æ­¥æ•°: é€šå¸¸ 100+ æ­¥

Flow Matching (Ï€â‚€.â‚…):
- å‰å‘: çº¿æ€§æ’å€¼ x_t = t*noise + (1-t)*actions
- è®­ç»ƒ: é¢„æµ‹é€Ÿåº¦åœº v = noise - actions
- æ¨ç†: ODE æ±‚è§£å™¨ (Euler)
- æ­¥æ•°: é€šå¸¸ 10-20 æ­¥ âœ…

ä¼˜åŠ¿:
âœ… æ›´ç®€æ´çš„æ•°å­¦å½¢å¼
âœ… æ›´å°‘çš„æ¨ç†æ­¥æ•°
âœ… è®­ç»ƒæ›´ç¨³å®š
"""
```

---

## ğŸ§© æ¨¡å—è¯¦è§£

### æ¨¡å— 1: embed_prefix (è§†è§‰+è¯­è¨€ç¼–ç )

```python
# ä½ç½®: modeling_pi05.py:616-657

def embed_prefix(images, img_masks, tokens, masks):
    """
    ç¼–ç è§‚æµ‹å‰ç¼€ (å›¾åƒ + è¯­è¨€æŒ‡ä»¤)

    è¾“å…¥:
      images: [B, n_cam, 3, 224, 224]
      img_masks: [B, n_cam] bool (å“ªäº›ç›¸æœºæœ‰æ•ˆ)
      tokens: [B, N] è¯­è¨€ token IDs
      masks: [B, N] bool (å“ªäº› token ä¸æ˜¯ padding)

    è¾“å‡º:
      embs: [B, 196+N, 2048] ç¼–ç åçš„åµŒå…¥
      pad_masks: [B, 196+N] bool
      att_masks: [B, 196+N] int (0 = prefix LM, 1 = causal)
    """
    embs = []
    pad_masks = []
    att_masks = []

    # ============ 1. å¤„ç†å›¾åƒ ============
    for img, img_mask in zip(images, img_masks):
        # 1.1 SigLIP Vision Encoder (PaliGemma çš„è§†è§‰éƒ¨åˆ†)
        img_emb = paligemma.embed_image(img)  # [n_cam, 196, 2048]
        # 196 = 14x14 patches (224/16=14)

        # 1.2 Mask æ‰æ— æ•ˆç›¸æœº
        img_emb = img_emb * img_mask[:, None, None]

        embs.append(img_emb.flatten(0, 1))  # [n_cam*196, 2048]
        pad_masks.append(img_mask.repeat_interleave(196))
        att_masks += [0] * (n_cam * 196)  # â­ å›¾åƒ token ç”¨ Prefix-LM

    # ============ 2. å¤„ç†è¯­è¨€ ============
    # 2.1 Gemma Text Embedding
    lang_emb = paligemma.embed_text(tokens)  # [B, N, 2048]

    # 2.2 Mask æ‰ padding
    lang_emb = lang_emb * masks[:, :, None]

    embs.append(lang_emb)
    pad_masks.append(masks)
    att_masks += [0] * N  # â­ è¯­è¨€ token ä¹Ÿç”¨ Prefix-LM

    # ============ 3. æ‹¼æ¥ ============
    embs = torch.cat(embs, dim=1)  # [B, 196+N, 2048]
    pad_masks = torch.cat(pad_masks, dim=1)  # [B, 196+N]
    att_masks = torch.tensor(att_masks)  # [196+N]

    return embs, pad_masks, att_masks
```

**å…³é”®ç‚¹:**
- å›¾åƒé€šè¿‡ **SigLIP** (æ¯” CLIP æ›´å¼ºçš„è§†è§‰ç¼–ç å™¨)
- è¯­è¨€é€šè¿‡ **Gemma** çš„ Embedding å±‚
- æ‰€æœ‰ prefix token ä½¿ç”¨ `att_mask=0` (Prefix-LMï¼Œå½¼æ­¤å¯è§)

---

### æ¨¡å— 2: embed_suffix (åŠ¨ä½œ+æ—¶é—´ç¼–ç ) â­

```python
# ä½ç½®: modeling_pi05.py:659-719

def embed_suffix(noisy_actions, timestep):
    """
    ç¼–ç åŠ¨ä½œåç¼€ + æ—¶é—´æ­¥ (Ï€â‚€.â‚… çš„æ ¸å¿ƒåˆ›æ–°)

    è¾“å…¥:
      noisy_actions: [B, 50, 7] å™ªå£°åŠ¨ä½œ x_t
      timestep: [B] æ—¶é—´æ­¥ t âˆˆ [0, 1]

    è¾“å‡º:
      embs: [B, 50, 1024] åŠ¨ä½œåµŒå…¥
      pad_masks: [B, 50] bool
      att_masks: [B, 50] int (å› æœ mask)
      adarms_cond: [B, 1024] â­ æ—¶é—´æ¡ä»¶ (AdaRMS ä½¿ç”¨)
    """
    embs = []
    pad_masks = []
    att_masks = []

    # ============ 1. ç¼–ç æ—¶é—´æ­¥ ============
    # 1.1 æ­£å¼¦-ä½™å¼¦ä½ç½®ç¼–ç 
    time_emb = create_sinusoidal_pos_embedding(
        timestep,  # [B]
        dimension=1024,
        min_period=4e-3,
        max_period=4.0,
        device=timestep.device
    )  # [B, 1024]

    # ç¤ºä¾‹: t=0.5
    # time_emb = [sin(0.5*Ï€/4e-3), cos(0.5*Ï€/4e-3),
    #             sin(0.5*Ï€/8e-3), cos(0.5*Ï€/8e-3), ...]

    # 1.2 é€šè¿‡ MLP è½¬æ¢
    time_emb = time_mlp_out(
        F.silu(time_mlp_in(time_emb))
    )  # [B, 1024]

    # â­ å…³é”®: æ—¶é—´å•ç‹¬ä¿å­˜ï¼Œä½œä¸º AdaRMS æ¡ä»¶
    adarms_cond = time_emb  # [B, 1024]

    # ============ 2. ç¼–ç åŠ¨ä½œ ============
    action_emb = action_in_proj(noisy_actions)  # [B, 50, 7] -> [B, 50, 1024]

    # â­ Ï€â‚€.â‚… çš„å…³é”®: åŠ¨ä½œå’Œæ—¶é—´**ä¸æ‹¼æ¥**
    action_time_emb = action_emb  # åªä¿ç•™åŠ¨ä½œåµŒå…¥

    embs.append(action_time_emb)
    pad_masks.append(torch.ones(B, 50, dtype=torch.bool))

    # ============ 3. è®¾ç½®å› æœ mask ============
    # ç¬¬ä¸€ä¸ªåŠ¨ä½œ token: att_mask=1 (å¼€å§‹æ–°çš„å› æœåºåˆ—)
    # åç»­åŠ¨ä½œ token: att_mask=0 (ç»§ç»­å› æœåºåˆ—)
    att_masks += [1] + [0] * 49

    # ============ 4. æ‹¼æ¥ ============
    embs = torch.cat(embs, dim=1)  # [B, 50, 1024]
    pad_masks = torch.cat(pad_masks, dim=1)  # [B, 50]
    att_masks = torch.tensor(att_masks)  # [50]

    return embs, pad_masks, att_masks, adarms_cond


# ============ å¯¹æ¯”: Ï€â‚€ çš„ embed_suffix ============
def embed_suffix_pi0(noisy_actions, timestep):
    time_emb = create_sinusoidal_pos_embedding(...)  # [B, 1024]
    action_emb = action_in_proj(noisy_actions)       # [B, 50, 1024]

    # â­ Ï€â‚€: æ‹¼æ¥æ—¶é—´åˆ°æ¯ä¸ªåŠ¨ä½œ token
    time_expanded = time_emb[:, None, :].expand(-1, 50, -1)  # [B, 50, 1024]
    action_time = torch.cat([action_emb, time_expanded], dim=-1)  # [B, 50, 2048]

    # é€šè¿‡ 2x MLP èåˆ
    action_time_emb = action_time_mlp_out(
        F.silu(action_time_mlp_in(action_time))
    )  # [B, 50, 1024]

    return action_time_emb, None  # âŒ æ—  AdaRMS æ¡ä»¶
```

**å…³é”®å·®å¼‚æ€»ç»“:**

| æ­¥éª¤ | Ï€â‚€ | Ï€â‚€.â‚… |
|------|-----|------|
| æ—¶é—´ç¼–ç  | æ­£å¼¦-ä½™å¼¦ | æ­£å¼¦-ä½™å¼¦ (ç›¸åŒ) |
| åŠ¨ä½œæŠ•å½± | Linear(7â†’1024) | Linear(7â†’1024) (ç›¸åŒ) |
| **èåˆæ–¹å¼** | **Concat + 2x MLP** | **åˆ†ç¦» + time_mlp** |
| **æ—¶é—´æ¡ä»¶** | **âŒ æ— ** | **âœ… AdaRMS** |
| **å‚æ•°é‡** | **é«˜ (2x MLP)** | **ä½ (1x MLP)** |

---

### æ¨¡å— 3: PaliGemmaWithExpertModel (åŒæ¨¡å‹æ¶æ„)

```python
# ä½ç½®: modeling_pi05.py:343-527

class PaliGemmaWithExpertModel(nn.Module):
    """
    åŒæ¨¡å‹æ¶æ„:
    1. PaliGemma: å¤„ç†è§†è§‰+è¯­è¨€ (prefix)
    2. Gemma Expert: å¤„ç†åŠ¨ä½œ (suffix)
    """

    def __init__(
        self,
        paligemma_config,
        action_expert_config,
        use_adarms=[False, True],  # â­ [PaliGemma, Action Expert]
    ):
        # ============ 1. PaliGemma (2B) ============
        self.paligemma = PaliGemmaForConditionalGeneration(...)
        # - SigLIP Vision Encoder (400M)
        # - Gemma 2B Language Model
        # - No AdaRMS (use_adarms[0] = False)

        # ============ 2. Action Expert (300M) ============
        self.gemma_expert = GemmaForCausalLM(...)
        # - Gemma 300M Language Model
        # - With AdaRMS (use_adarms[1] = True) â­

        # è®¾ç½® AdaRMS é…ç½®
        self.paligemma.config.text_config.use_adarms = False
        self.gemma_expert.config.use_adarms = True
        self.gemma_expert.config.adarms_cond_dim = 1024  # â­

    def forward(self, prefix_embs, suffix_embs, attention_mask, position_ids, adarms_cond):
        """
        å‰å‘ä¼ æ’­

        è¾“å…¥:
          prefix_embs: [B, 196+N, 2048]
          suffix_embs: [B, 50, 1024]
          attention_mask: [B, 1, L, L] 4D mask
          position_ids: [B, L]
          adarms_cond: [None, [B, 1024]] â­ åªç”¨äº Action Expert

        è¾“å‡º:
          suffix_hidden: [B, 50, 1024] Action expert çš„è¾“å‡º
        """
        # ============ Step 1: PaliGemma å¤„ç† prefix ============
        prefix_hidden = self.paligemma.language_model(
            inputs_embeds=prefix_embs,
            attention_mask=attention_mask[:, :, :prefix_len, :prefix_len],
            position_ids=position_ids[:, :prefix_len],
            adarms_cond=None  # â­ PaliGemma ä¸ç”¨ AdaRMS
        )
        # prefix_hidden: [B, 196+N, 2048]

        # ============ Step 2: Action Expert å¤„ç† suffix ============
        # 2.1 æŠ•å½± prefix åˆ° action expert ç»´åº¦
        prefix_proj = project_down(prefix_hidden)  # [B, 196+N, 1024]

        # 2.2 æ‹¼æ¥ prefix å’Œ suffix
        full_input = torch.cat([prefix_proj, suffix_embs], dim=1)  # [B, 196+N+50, 1024]

        # 2.3 é€šè¿‡ Action Expert
        full_hidden = self.gemma_expert(
            inputs_embeds=full_input,
            attention_mask=attention_mask,
            position_ids=position_ids,
            adarms_cond=adarms_cond[1]  # â­ [B, 1024] æ—¶é—´æ¡ä»¶
        )
        # full_hidden: [B, 196+N+50, 1024]

        # 2.4 æå– suffix éƒ¨åˆ†
        suffix_hidden = full_hidden[:, -50:, :]  # [B, 50, 1024]

        return suffix_hidden
```

**ä¸ºä»€ä¹ˆç”¨åŒæ¨¡å‹ï¼Ÿ**
1. **è§£è€¦ä»»åŠ¡**: PaliGemma ä¸“æ³¨ç†è§£è§‚æµ‹ï¼ŒGemma Expert ä¸“æ³¨ç”ŸæˆåŠ¨ä½œ
2. **å‚æ•°æ•ˆç‡**: Action expert åªéœ€ 300Mï¼Œä¸éœ€è¦ 2B
3. **AdaRMS ä¸“ç”¨**: åªåœ¨ action expert ä½¿ç”¨ AdaRMSï¼Œå‡å°‘è®¡ç®—

---

### æ¨¡å— 4: AdaRMS Layer (æ¡ä»¶å½’ä¸€åŒ–)

```python
# ä½ç½®: modeling_pi05.py:228-300

class AdaRMSNorm(nn.Module):
    """
    Adaptive RMS Normalization
    """

    def __init__(self, hidden_size, cond_dim):
        super().__init__()
        # åŸºç¡€ç¼©æ”¾å‚æ•°
        self.weight = nn.Parameter(torch.ones(hidden_size))

        # æ¡ä»¶æŠ•å½± (å­¦ä¹  scale å’Œ shift)
        self.cond_proj = nn.Linear(cond_dim, 2 * hidden_size)
        # è¾“å‡ºç»´åº¦ = 2 * hidden_size (å‰åŠéƒ¨åˆ†æ˜¯ scale, ååŠéƒ¨åˆ†æ˜¯ shift)

        self.eps = 1e-6

    def forward(self, hidden_states, cond):
        """
        è¾“å…¥:
          hidden_states: [B, T, D] ç‰¹å¾
          cond: [B, C] æ¡ä»¶ (æ—¶é—´æ­¥ç¼–ç )

        è¾“å‡º:
          output: [B, T, D] å½’ä¸€åŒ–åçš„ç‰¹å¾
          gate: [B, D] ç¼©æ”¾å› å­ (ç”¨äºå¯è§†åŒ–)
        """
        # ============ 1. æ ‡å‡† RMS å½’ä¸€åŒ– ============
        # è®¡ç®— RMS
        variance = hidden_states.pow(2).mean(-1, keepdim=True)  # [B, T, 1]
        rms = torch.sqrt(variance + self.eps)  # [B, T, 1]

        # å½’ä¸€åŒ–
        normalized = hidden_states / rms  # [B, T, D]

        # åº”ç”¨åŸºç¡€ç¼©æ”¾
        normalized = self.weight * normalized  # [B, T, D]

        # ============ 2. æ¡ä»¶è°ƒåˆ¶ (AdaRMS æ ¸å¿ƒ) ============
        if cond is not None:
            # 2.1 ä»æ¡ä»¶ç”Ÿæˆ scale å’Œ shift
            cond_out = self.cond_proj(cond)  # [B, C] -> [B, 2*D]
            scale, shift = cond_out.chunk(2, dim=-1)  # [B, D], [B, D]

            # 2.2 åº”ç”¨è°ƒåˆ¶
            # scale: åŸºå‡†ä¸º 1 (åŠ æ€§)
            # shift: åŸºå‡†ä¸º 0
            gate = 1 + scale  # [B, D]
            output = gate[:, None, :] * normalized + shift[:, None, :]
            # [B, D] -> [B, 1, D] å¹¿æ’­åˆ° [B, T, D]
        else:
            # æ— æ¡ä»¶ (æ ‡å‡† RMSNorm)
            output = normalized
            gate = torch.ones_like(self.weight)

        return output, gate


# ============ ç¤ºä¾‹: AdaRMS çš„æ•ˆæœ ============
"""
è¾“å…¥ç‰¹å¾: hidden_states = [B, 50, 1024]
æ¡ä»¶: adarms_cond = [B, 1024] (æ—¶é—´æ­¥ t=0.5)

1. æ ‡å‡†å½’ä¸€åŒ–:
   normalized = hidden_states / rms(hidden_states)
   # æ‰€æœ‰æ—¶é—´æ­¥ t ä½¿ç”¨ç›¸åŒçš„å½’ä¸€åŒ–

2. AdaRMS:
   scale_0.5, shift_0.5 = cond_proj(adarms_cond_0.5)
   output_0.5 = (1 + scale_0.5) * normalized + shift_0.5

   # ä¸åŒæ—¶é—´æ­¥ t æœ‰ä¸åŒçš„ scale å’Œ shift
   t=0.1: scale=[1.2, 0.8, ...], shift=[0.1, -0.2, ...]
   t=0.5: scale=[1.0, 1.0, ...], shift=[0.0, 0.0, ...]
   t=0.9: scale=[0.8, 1.3, ...], shift=[-0.1, 0.3, ...]

â†’ ç½‘ç»œå¯ä»¥æ ¹æ®æ—¶é—´æ­¥åŠ¨æ€è°ƒæ•´æ¯å±‚çš„ç‰¹å¾åˆ†å¸ƒ
"""
```

---

## ğŸ†š ä¸ Ï€â‚€ã€ACTã€DP çš„å¯¹æ¯”

### å…¨é¢å¯¹æ¯”è¡¨

| å¯¹æ¯”ç»´åº¦ | ACT | Diffusion Policy | Ï€â‚€ | Ï€â‚€.â‚… |
|---------|-----|------------------|-----|------|
| **å‘å¸ƒæ—¶é—´** | 2022 | 2023 | 2024.10 | 2025.01 |
| **æ ¸å¿ƒç½‘ç»œ** | Transformer | ResNet + U-Net | PaliGemma + Gemma | PaliGemma + Gemma |
| **è¾“å…¥æ¨¡æ€** | å›¾åƒ + çŠ¶æ€ | å›¾åƒ + çŠ¶æ€ | å›¾åƒ + è¯­è¨€ + çŠ¶æ€ | å›¾åƒ + è¯­è¨€ |
| **åŠ¨ä½œå»ºæ¨¡** | VAE | Diffusion | Flow Matching | Flow Matching |
| **æ—¶é—´è°ƒåˆ¶** | - | FiLM | Token concat | **AdaRMS** â­ |
| **çŠ¶æ€å¤„ç†** | ç›´æ¥æ‹¼æ¥ | ç›´æ¥æ‹¼æ¥ | state_proj | **ç¦»æ•£åŒ–** â­ |
| **æ¨ç†æ­¥æ•°** | 1 | 100 | 10 | 10 |
| **å‚æ•°é‡** | ~100M | ~50M | ~2.5B | ~2.3B |
| **é›¶æ ·æœ¬èƒ½åŠ›** | âŒ | âŒ | âœ… | âœ…âœ… |
| **è®­ç»ƒç¨³å®šæ€§** | â­â­â­ | â­â­ | â­â­â­ | â­â­â­â­ |
| **æ¨ç†é€Ÿåº¦** | æœ€å¿« | æ…¢ | ä¸­ç­‰ | ä¸­ç­‰ |

### ä»£ç ç»“æ„å¯¹æ¯”

```python
# ============ ACT æ¨ç† ============
def act_forward(observation):
    # ç¼–ç è§‚æµ‹
    encoder_out = encoder(observation)
    # è‡ªå›å½’è§£ç 
    actions = decoder(encoder_out)
    return actions  # 1æ¬¡å‰å‘

# ============ DP æ¨ç† ============
def dp_forward(observation):
    cond = encoder(observation)
    sample = randn(B, horizon, action_dim)
    for t in [100, 99, ..., 1]:  # 100æ¬¡å‰å‘
        noise_pred = unet(sample, t, cond)  # FiLM è°ƒåˆ¶
        sample = scheduler.step(noise_pred, t, sample)
    return sample

# ============ Ï€â‚€ æ¨ç† ============
def pi0_forward(observation, language):
    # ç¼–ç  prefix
    prefix_embs = embed_prefix(obs, language)

    sample = randn(B, 50, 7)
    for t in [1.0, 0.9, ..., 0.0]:  # 10æ¬¡å‰å‘
        # â­ æ—¶é—´æ‹¼æ¥åˆ°åŠ¨ä½œ
        suffix_embs = embed_suffix_concat(sample, t)
        v_pred = model(prefix_embs, suffix_embs, adarms_cond=None)
        sample = sample + v_pred * dt
    return sample

# ============ Ï€â‚€.â‚… æ¨ç† ============
def pi05_forward(observation, language):
    # ç¼–ç  prefix
    prefix_embs = embed_prefix(obs, language)

    sample = randn(B, 50, 7)
    for t in [1.0, 0.9, ..., 0.0]:  # 10æ¬¡å‰å‘
        # â­ æ—¶é—´ä½œä¸º AdaRMS æ¡ä»¶
        suffix_embs, adarms_cond = embed_suffix_adarms(sample, t)
        v_pred = model(prefix_embs, suffix_embs, adarms_cond=adarms_cond)
        sample = sample + v_pred * dt
    return sample
```

### ä¼˜ç¼ºç‚¹æ€»ç»“

#### ACT
**ä¼˜åŠ¿:**
- âœ… æ¨ç†é€Ÿåº¦æœ€å¿«
- âœ… å®ç°ç®€å•
- âœ… è®­ç»ƒç¨³å®š

**åŠ£åŠ¿:**
- âŒ æ— é›¶æ ·æœ¬æ³›åŒ–
- âŒ éš¾ä»¥å¤„ç†å¤šæ¨¡æ€
- âŒ å•ä»»åŠ¡å­¦ä¹ 

---

#### Diffusion Policy
**ä¼˜åŠ¿:**
- âœ… åŠ¨ä½œå¹³æ»‘
- âœ… å¤šæ¨¡æ€èƒ½åŠ›
- âœ… å‚æ•°é‡å°

**åŠ£åŠ¿:**
- âŒ æ¨ç†æ…¢ (100æ­¥)
- âŒ æ— è¯­è¨€ç†è§£
- âŒ è®­ç»ƒä¸ç¨³å®š

---

#### Ï€â‚€
**ä¼˜åŠ¿:**
- âœ… é›¶æ ·æœ¬æ³›åŒ–
- âœ… è¯­è¨€ç†è§£
- âœ… Flow Matching (æ¯” Diffusion å¿«)

**åŠ£åŠ¿:**
- âŒ å‚æ•°é‡å¤§ (2.5B)
- âŒ éœ€è¦ state_proj
- âŒ Token concat æ•ˆç‡ä½

---

#### Ï€â‚€.â‚… (æœ€ä¼˜) â­
**ä¼˜åŠ¿:**
- âœ…âœ… æ›´å¼ºé›¶æ ·æœ¬æ³›åŒ–
- âœ… AdaRMS (æ›´å¼ºæ—¶é—´å»ºæ¨¡)
- âœ… å‚æ•°æ›´å°‘ (æ—  state_proj)
- âœ… è®­ç»ƒæ›´ç¨³å®š
- âœ… æ”¯æŒæ›´é•¿æŒ‡ä»¤ (200 tokens)

**åŠ£åŠ¿:**
- âŒ ä»éœ€å¤§ç®—åŠ› (2.3B æ¨¡å‹)
- âŒ æ¨ç†æ…¢äº ACT

---

## â“ å¸¸è§é¢è¯•é—®é¢˜

### åŸºç¡€æ¦‚å¿µé¢˜

**Q1: Ï€â‚€.â‚… ç›¸æ¯” Ï€â‚€ çš„æ ¸å¿ƒåˆ›æ–°æ˜¯ä»€ä¹ˆï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**æ ¸å¿ƒåˆ›æ–°: AdaRMS (Adaptive RMSNorm)**

**ä¸‰å¤§æ”¹è¿›:**

1. **æ—¶é—´æ¡ä»¶æ–¹å¼**
   - Ï€â‚€: Token concatenation (æ‹¼æ¥æ—¶é—´åˆ°æ¯ä¸ªåŠ¨ä½œ token)
   - Ï€â‚€.â‚…: AdaRMS conditioning (æ—¶é—´ä½œä¸ºå½’ä¸€åŒ–æ¡ä»¶)

   ```python
   # Ï€â‚€
   action_time = concat([action_emb, time_emb])  # 2x ç»´åº¦
   action_time_emb = MLP_2x(action_time)

   # Ï€â‚€.â‚…
   action_emb = MLP_1x(action)  # ä¿æŒåŸç»´åº¦
   adarms_cond = time_mlp(time_emb)  # å•ç‹¬å¤„ç†æ—¶é—´
   # æ—¶é—´åœ¨æ¯ä¸€å±‚é€šè¿‡ AdaRMS æ³¨å…¥
   ```

2. **å‚æ•°æ•ˆç‡**
   - ç§»é™¤ `state_proj` å±‚ (æ”¹ç”¨ç¦»æ•£åŒ–)
   - ç§»é™¤ `action_time_mlp` (æ”¹ç”¨ AdaRMS)
   - å‚æ•°å‡å°‘çº¦ 10-15%

3. **æ³›åŒ–èƒ½åŠ›**
   - Tokenizer é•¿åº¦: 48 â†’ 200 tokens
   - å½’ä¸€åŒ–ç­–ç•¥: MEAN_STD â†’ QUANTILES
   - æ›´é€‚åˆå¼€æ”¾ä¸–ç•Œä»»åŠ¡

</details>

---

**Q2: ä»€ä¹ˆæ˜¯ AdaRMSï¼Ÿå®ƒå¦‚ä½•å·¥ä½œï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**AdaRMS = Adaptive Root Mean Square Normalization**

**å·¥ä½œåŸç†:**

```python
# æ ‡å‡† RMSNorm
normalized = hidden_states / sqrt(mean(hidden_states^2))
output = weight * normalized

# AdaRMS (æ¡ä»¶å½’ä¸€åŒ–)
normalized = hidden_states / sqrt(mean(hidden_states^2))
scale, shift = MLP(adarms_cond).chunk(2)  # ä»æ—¶é—´æ¡ä»¶å­¦ä¹ 
output = (1 + scale) * (weight * normalized) + shift
```

**æ ¸å¿ƒæ€æƒ³:**
- é€šè¿‡æ¡ä»¶ä¿¡æ¯ (æ—¶é—´æ­¥) åŠ¨æ€è°ƒæ•´å½’ä¸€åŒ–çš„ scale å’Œ shift
- ç±»ä¼¼å›¾åƒç”Ÿæˆä¸­çš„ AdaIN (Adaptive Instance Normalization)
- æ¯ä¸ªæ—¶é—´æ­¥æœ‰ä¸åŒçš„å½’ä¸€åŒ–å‚æ•°

**ä¼˜åŠ¿:**
1. æ›´å¼ºçš„æ—¶é—´å»ºæ¨¡èƒ½åŠ› (æ¯å±‚éƒ½æ„ŸçŸ¥æ—¶é—´)
2. å‚æ•°æ›´å°‘ (æ— éœ€æ‹¼æ¥)
3. è®­ç»ƒæ›´ç¨³å®š (å½’ä¸€åŒ–æ›´é²æ£’)

**ä»£ç ä½ç½®:**
- [modeling_pi05.py:238-240](src/lerobot/policies/pi05/modeling_pi05.py#L238-L240) - ä½¿ç”¨ä½ç½®
- [modeling_pi05.py:692-693](src/lerobot/policies/pi05/modeling_pi05.py#L692-L693) - æ¡ä»¶ç”Ÿæˆ

</details>

---

**Q3: Flow Matching å’Œ Diffusion æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**æ ¸å¿ƒåŒºåˆ«:**

| ç»´åº¦ | Diffusion | Flow Matching |
|------|-----------|---------------|
| **å‰å‘è¿‡ç¨‹** | é€æ­¥åŠ å™ªå£° (é©¬å°”å¯å¤«é“¾) | çº¿æ€§æ’å€¼ (ç¡®å®šæ€§) |
| **å­¦ä¹ ç›®æ ‡** | é¢„æµ‹å™ªå£° Îµ | é¢„æµ‹é€Ÿåº¦åœº v |
| **æ¨ç†æ–¹å¼** | é€†å‘å»å™ª (SDE/ODE) | å‰å‘ ODE ç§¯åˆ† |
| **æ•°å­¦å½¢å¼** | å¤æ‚ (SDE ç†è®º) | ç®€æ´ (è¿ç»­å½’ä¸€åŒ–æµ) |
| **è®­ç»ƒç¨³å®šæ€§** | ä¸­ç­‰ | æ›´å¥½ |
| **æ¨ç†æ­¥æ•°** | 100+ | 10-20 |

**æ•°å­¦å…¬å¼å¯¹æ¯”:**

```python
# Diffusion (DDPM)
# å‰å‘: x_t = sqrt(Î±_t)*x_0 + sqrt(1-Î±_t)*Îµ
# è®­ç»ƒ: å­¦ä¹  Îµ_Î¸(x_t, t) â‰ˆ Îµ
# æ¨ç†: x_{t-1} = (x_t - sqrt(1-Î±_t)*Îµ_Î¸(x_t,t)) / sqrt(Î±_t)

# Flow Matching
# å‰å‘: x_t = t*x_1 + (1-t)*x_0  (çº¿æ€§æ’å€¼)
# è®­ç»ƒ: å­¦ä¹  v_Î¸(x_t, t) â‰ˆ x_1 - x_0
# æ¨ç†: dx/dt = v_Î¸(x_t, t),  x_0 = x_1 + âˆ«_1^0 v_Î¸ dt
```

**ä¸ºä»€ä¹ˆé€‰ Flow Matchingï¼Ÿ**
1. âœ… æ›´ç®€æ´çš„æ•°å­¦ (æ— éœ€å®šä¹‰å™ªå£° schedule)
2. âœ… è®­ç»ƒæ›´ç¨³å®š (ç›®æ ‡æ›´ç›´æ¥)
3. âœ… æ¨ç†æ›´å¿« (æ›´å°‘æ­¥æ•°)
4. âœ… æ›´æ˜“æ‰©å±• (å¯ç”¨ä¸åŒ ODE solver)

</details>

---

### å®ç°ç»†èŠ‚é¢˜

**Q4: Ï€â‚€.â‚… çš„æ³¨æ„åŠ› mask æ˜¯å¦‚ä½•æ„å»ºçš„ï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**Prefix-LM Attention Pattern**

Ï€â‚€.â‚… ä½¿ç”¨æ··åˆæ³¨æ„åŠ›æ¨¡å¼:
- **Prefix (å›¾åƒ+è¯­è¨€)**: åŒå‘æ³¨æ„åŠ› (å½¼æ­¤å¯è§)
- **Suffix (åŠ¨ä½œ)**: å› æœæ³¨æ„åŠ› (åªçœ‹è¿‡å»)

**æ„å»ºè¿‡ç¨‹:**

```python
# Step 1: å®šä¹‰ att_masks (1=å¼€å§‹æ–°çš„å› æœå—, 0=ç»§ç»­)
att_masks = []

# Prefix: æ‰€æœ‰ token ç”¨ 0 (åŒå‘)
att_masks += [0] * (196 + N)  # å›¾åƒ + è¯­è¨€

# Suffix: ç¬¬ä¸€ä¸ªç”¨ 1ï¼Œåç»­ç”¨ 0 (å› æœ)
att_masks += [1] + [0] * 49  # åŠ¨ä½œ

# Step 2: è½¬æ¢ä¸º 2D mask
cumsum = torch.cumsum(att_masks, dim=1)
# ç¤ºä¾‹: [0,0,0,1,1,1] -> cumsum = [0,0,0,1,2,3]

att_2d_mask = cumsum[:, None, :] <= cumsum[:, :, None]
# cumsum[:, None, :] = [[0,0,0,1,2,3]]  (è¡Œ)
# cumsum[:, :, None] = [[0],[0],[0],[1],[2],[3]]  (åˆ—)
# <= æ¯”è¾ƒå¾—åˆ°:
# [[T, T, T, F, F, F],  # Prefix å¯ä»¥çœ‹æ‰€æœ‰ prefix
#  [T, T, T, F, F, F],
#  [T, T, T, F, F, F],
#  [F, F, F, T, F, F],  # Action åªçœ‹è‡ªå·±å’Œä¹‹å‰
#  [F, F, F, T, T, F],
#  [F, F, F, T, T, T]]
```

**å¯è§†åŒ–:**

```
     Img0...Img195  Lang0...LangN  Act0...Act49
Img0    åŒå‘            åŒå‘          âŒ
...     åŒå‘            åŒå‘          âŒ
Lang0   åŒå‘            åŒå‘          âŒ
...     åŒå‘            åŒå‘          âŒ
Act0    âŒ             âŒ            å› æœ â†’
Act1    âŒ             âŒ            å› æœ â†’
...     âŒ             âŒ            å› æœ â†’
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**
- å›¾åƒå’Œè¯­è¨€æ˜¯**è§‚æµ‹ä¸Šä¸‹æ–‡**ï¼Œåº”è¯¥å½¼æ­¤å¯è§
- åŠ¨ä½œæ˜¯**ç”Ÿæˆåºåˆ—**ï¼Œåº”è¯¥å› æœç”Ÿæˆ (ä¸èƒ½çœ‹æœªæ¥)

**ä»£ç ä½ç½®:**
- [modeling_pi05.py:93-139](src/lerobot/policies/pi05/modeling_pi05.py#L93-L139) - `make_att_2d_masks`

</details>

---

**Q5: ä¸ºä»€ä¹ˆ Ï€â‚€.â‚… å»æ‰äº† state_proj å±‚ï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**åŸå› : ä½¿ç”¨ Quantile Normalization ç¦»æ•£åŒ–çŠ¶æ€**

**Ï€â‚€ çš„æ–¹å¼:**
```python
# é…ç½®
discrete_state_input: False  # çŠ¶æ€æ˜¯è¿ç»­çš„
normalization: MEAN_STD      # å‡å€¼æ ‡å‡†å·®å½’ä¸€åŒ–

# æ¨¡å‹
state_proj = nn.Linear(max_state_dim, hidden_dim)  # éœ€è¦æŠ•å½±å±‚

def forward(state):
    state_normalized = (state - mean) / std  # å½’ä¸€åŒ–åˆ° ~N(0,1)
    state_emb = state_proj(state_normalized)  # æŠ•å½±åˆ° embedding ç©ºé—´
```

**Ï€â‚€.â‚… çš„æ–¹å¼:**
```python
# é…ç½®
discrete_state_input: True   # â­ çŠ¶æ€æ˜¯ç¦»æ•£çš„
normalization: QUANTILES     # åˆ†ä½æ•°å½’ä¸€åŒ–

# æ¨¡å‹
# âŒ æ²¡æœ‰ state_proj å±‚

def forward(state):
    # çŠ¶æ€å·²ç»åœ¨æ•°æ®å¤„ç†æ—¶ç¦»æ•£åŒ–ä¸º token IDs
    state_discrete = quantile_normalize(state)  # [0, 1, 2, ..., 255]
    state_emb = embedding_layer(state_discrete)  # ç›´æ¥ embedding
```

**Quantile Normalization ç¤ºä¾‹:**
```python
# åŸå§‹çŠ¶æ€: [0.1, 0.5, 0.9, 0.3]

# Step 1: è®¡ç®—è®­ç»ƒæ•°æ®çš„åˆ†ä½æ•°
quantiles = compute_quantiles(train_data, n_bins=256)
# quantiles = [p_0, p_1, ..., p_255]

# Step 2: ç¦»æ•£åŒ–
state_discrete = []
for s in state:
    bin_id = find_bin(s, quantiles)  # æ‰¾åˆ° s è½åœ¨å“ªä¸ª bin
    state_discrete.append(bin_id)
# state_discrete = [25, 128, 230, 76]  (ç¦»æ•£ ID)

# Step 3: åµŒå…¥
state_emb = embedding_layer(state_discrete)
# ç±»ä¼¼è¯­è¨€ token çš„å¤„ç†æ–¹å¼
```

**ä¼˜åŠ¿:**
1. âœ… å‡å°‘å‚æ•°é‡ (çœæ‰ Linear å±‚)
2. âœ… æ›´å¼ºæ³›åŒ– (ç¦»æ•£è¡¨ç¤ºæ›´é²æ£’)
3. âœ… ç»Ÿä¸€å¤„ç† (çŠ¶æ€å’Œè¯­è¨€éƒ½æ˜¯ tokens)
4. âœ… å¯¹å¼‚å¸¸å€¼æ›´é²æ£’

**åŠ£åŠ¿:**
- âŒ éœ€è¦é¢„å…ˆè®¡ç®—åˆ†ä½æ•°
- âŒ ç¦»æ•£åŒ–å¯èƒ½æŸå¤±ä¿¡æ¯

</details>

---

**Q6: Ï€â‚€.â‚… å¦‚ä½•å¤„ç†å¤šä¸ªç›¸æœºçš„å›¾åƒï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**å¤„ç†æµç¨‹:**

```python
# è¾“å…¥: images [B, n_cam, 3, 224, 224]
# ä¾‹å¦‚: n_cam=3 (æ‰‹è…•ç›¸æœºã€ç¬¬ä¸‰äººç§°ç›¸æœºã€ä¿¯è§†ç›¸æœº)

def embed_prefix(images, img_masks):
    embs = []

    # é€ä¸ªç›¸æœºå¤„ç†
    for cam_idx in range(n_cam):
        img = images[:, cam_idx]  # [B, 3, 224, 224]

        # 1. SigLIP Vision Encoder
        img_patches = vision_encoder(img)  # [B, 196, 2048]
        # 196 = 14x14 patches (æ¯ä¸ª 16x16 åƒç´ )

        # 2. Mask æ‰æ— æ•ˆç›¸æœº
        if not img_masks[:, cam_idx]:
            img_patches = torch.zeros_like(img_patches)

        embs.append(img_patches)

    # æ‹¼æ¥æ‰€æœ‰ç›¸æœº
    all_img_embs = torch.cat(embs, dim=1)  # [B, 196*n_cam, 2048]
    # ä¾‹å¦‚: 3ä¸ªç›¸æœº -> [B, 588, 2048]

    return all_img_embs
```

**æ³¨æ„åŠ›æ¨¡å¼:**
- æ‰€æœ‰ç›¸æœºçš„ patches å½¼æ­¤å¯è§ (åŒå‘æ³¨æ„åŠ›)
- æ¯ä¸ªç›¸æœºçš„ patches æ²¡æœ‰ç‰¹æ®Šçš„ç›¸å¯¹ä½ç½®ç¼–ç 
- ç½‘ç»œè‡ªåŠ¨å­¦ä¹ ä¸åŒç›¸æœºçš„ç‰¹å¾

**ç¤ºä¾‹:**
```
ç›¸æœº1: [patch_0, patch_1, ..., patch_195] (196ä¸ª)
ç›¸æœº2: [patch_0, patch_1, ..., patch_195] (196ä¸ª)
ç›¸æœº3: [patch_0, patch_1, ..., patch_195] (196ä¸ª)
                 â†“ concat
å®Œæ•´åºåˆ—: [C1_p0, C1_p1, ..., C1_p195, C2_p0, ..., C3_p195] (588ä¸ª)
```

**ä»£ç ä½ç½®:**
- [modeling_pi05.py:625-640](src/lerobot/policies/pi05/modeling_pi05.py#L625-L640) - å›¾åƒç¼–ç 

</details>

---

### è®­ç»ƒä¸è°ƒå‚é¢˜

**Q7: Ï€â‚€.â‚… çš„è®­ç»ƒä¸ç¨³å®šæ€ä¹ˆåŠï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ:**

**1. Loss çˆ†ç‚¸/NaN**

```python
# æ£€æŸ¥é¡¹:
# 1. æ¢¯åº¦è£å‰ª
optimizer_grad_clip_norm: float = 1.0  # é»˜è®¤ 1.0ï¼Œå¯ä»¥é™ä½åˆ° 0.5

# 2. å­¦ä¹ ç‡
optimizer_lr: float = 2.5e-5  # å¦‚æœä¸ç¨³å®šï¼Œé™åˆ° 1e-5

# 3. æ··åˆç²¾åº¦è®­ç»ƒ
dtype: str = "bfloat16"  # æ¯” float16 æ›´ç¨³å®š
# æˆ–è€…ç”¨ float32 (æ›´æ…¢ä½†æ›´ç¨³å®š)
```

**2. åŠ¨ä½œé¢„æµ‹ä¸åˆç†**

```python
# æ£€æŸ¥å½’ä¸€åŒ–:
# 1. ç¡®è®¤ actions åœ¨ [-1, 1] èŒƒå›´
print(batch["action"].min(), batch["action"].max())

# 2. ä½¿ç”¨ QUANTILES å½’ä¸€åŒ–
normalization_mapping: dict[str, NormalizationMode] = {
    "ACTION": NormalizationMode.QUANTILES,  # æ¯” MEAN_STD æ›´é²æ£’
}

# 3. æ¨ç†æ—¶è£å‰ª
clip_sample: bool = True
clip_sample_range: float = 1.0
```

**3. æ¨¡å‹ä¸æ”¶æ•›**

```python
# è°ƒæ•´ warmup:
scheduler_warmup_steps: int = 1_000  # å¢åŠ åˆ° 2000-3000

# è°ƒæ•´ batch size:
# å»ºè®®: batch_size >= 16
# å¦‚æœ GPU å†…å­˜ä¸å¤Ÿï¼Œä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

# å¯ç”¨ gradient checkpointing:
gradient_checkpointing: bool = True  # å‡å°‘å†…å­˜ï¼Œå…è®¸æ›´å¤§ batch
```

**4. æ—¶é—´é‡‡æ ·ä¸å¹³è¡¡**

```python
# æ£€æŸ¥æ—¶é—´åˆ†å¸ƒ:
time_sampling_beta_alpha: float = 1.5  # æ§åˆ¶ Beta åˆ†å¸ƒå½¢çŠ¶
time_sampling_beta_beta: float = 1.0

# å¦‚æœæƒ³æ›´å¤šè®­ç»ƒå›°éš¾çš„æ—¶é—´æ­¥ (t æ¥è¿‘ 1):
# å¢å¤§ alpha: 1.5 -> 2.0

# å¦‚æœæƒ³å‡åŒ€é‡‡æ ·:
# alpha=1.0, beta=1.0 (å‡åŒ€åˆ†å¸ƒ)
```

**è°ƒè¯•æ£€æŸ¥æ¸…å•:**
- [ ] æ‰“å°ç¬¬ä¸€ä¸ª batch çš„ç»Ÿè®¡ä¿¡æ¯
- [ ] æ£€æŸ¥ actions/images çš„èŒƒå›´
- [ ] å¯è§†åŒ–æ—¶é—´æ­¥åˆ†å¸ƒ
- [ ] æ£€æŸ¥æ¢¯åº¦èŒƒæ•° (`grad_norm < 10`)
- [ ] ç›‘æ§ AdaRMS çš„ scale/shift å€¼
- [ ] éªŒè¯æ³¨æ„åŠ› mask æ˜¯å¦æ­£ç¡®

</details>

---

**Q8: å¦‚ä½•ä» Ï€â‚€ checkpoint å¾®è°ƒåˆ° Ï€â‚€.â‚…ï¼Ÿ**

<details>
<summary>ç‚¹å‡»æŸ¥çœ‹ç­”æ¡ˆ</summary>

**è¿ç§»ç­–ç•¥:**

Ï€â‚€ å’Œ Ï€â‚€.â‚… çš„æƒé‡**éƒ¨åˆ†å…¼å®¹**ï¼Œéœ€è¦æ˜ å°„:

```python
# å…¼å®¹çš„å±‚ (ç›´æ¥åŠ è½½):
âœ… PaliGemma éª¨å¹²
âœ… Action Expert éª¨å¹² (é™¤äº† AdaRMS)
âœ… action_in_proj
âœ… action_out_proj

# éœ€è¦æ˜ å°„çš„å±‚:
ğŸ”„ action_time_mlp_in/out â†’ time_mlp_in/out
âŒ state_proj (Ï€â‚€.â‚… æ²¡æœ‰)
âŒ AdaRMS å±‚ (Ï€â‚€ æ²¡æœ‰)
```

**ä»£ç å®ç°:**

```python
# modeling_pi05.py:1000-1090 æœ‰è‡ªåŠ¨æ˜ å°„é€»è¾‘

def load_pi0_checkpoint(pi05_model, pi0_ckpt_path):
    """ä» Ï€â‚€ checkpoint åŠ è½½åˆ° Ï€â‚€.â‚…"""

    pi0_state_dict = torch.load(pi0_ckpt_path)
    pi05_state_dict = pi05_model.state_dict()

    # 1. æ˜ å°„é”®å
    mapped_dict = {}
    for key, value in pi0_state_dict.items():
        if "action_time_mlp_in" in key:
            # Ï€â‚€: action_time_mlp_in (2x width)
            # Ï€â‚€.â‚…: time_mlp_in (1x width)
            # åªå–å‰åŠéƒ¨åˆ†æƒé‡
            new_key = key.replace("action_time_mlp_in", "time_mlp_in")
            mapped_dict[new_key] = value[:, :1024]  # æˆªæ–­

        elif "action_time_mlp_out" in key:
            new_key = key.replace("action_time_mlp_out", "time_mlp_out")
            mapped_dict[new_key] = value

        elif "state_proj" in key:
            # Ï€â‚€.â‚… æ²¡æœ‰ state_projï¼Œè·³è¿‡
            print(f"Skipping {key} (not in Ï€â‚€.â‚…)")
            continue

        elif "norm" in key and "adarms" not in key:
            # Ï€â‚€ çš„ norm å±‚ -> Ï€â‚€.â‚… çš„ AdaRMS (å…¼å®¹)
            mapped_dict[key] = value

        else:
            # å…¶ä»–å±‚ç›´æ¥å¤åˆ¶
            mapped_dict[key] = value

    # 2. åŠ è½½æƒé‡ (ä¸¥æ ¼æ¨¡å¼å…³é—­ï¼Œå…è®¸ç¼ºå¤±é”®)
    pi05_model.load_state_dict(mapped_dict, strict=False)

    # 3. æ–°åˆå§‹åŒ–çš„å±‚:
    # - AdaRMS çš„ cond_proj å±‚
    # - time_mlp (éƒ¨åˆ†æƒé‡æ¥è‡ª Ï€â‚€)

    return pi05_model


# ä½¿ç”¨:
pi05_model = PI05Policy(config)
pi05_model = load_pi0_checkpoint(pi05_model, "pi0_checkpoint.pth")

# å¾®è°ƒå»ºè®®:
# - é™ä½å­¦ä¹ ç‡: 1e-5 (æ¯”ä»å¤´è®­ç»ƒå° 10x)
# - å¢åŠ  warmup: 500 steps
# - å†»ç»“ PaliGemma: åªè®­ç»ƒ Action Expert
```

**æ³¨æ„äº‹é¡¹:**
- AdaRMS å±‚éœ€è¦ä»å¤´è®­ç»ƒ (Ï€â‚€ æ²¡æœ‰)
- `action_time_mlp` çš„æƒé‡éœ€è¦æˆªæ–­ (2x â†’ 1x)
- `state_proj` æƒé‡æ— æ³•è¿ç§» (Ï€â‚€.â‚… æ²¡æœ‰)

</details>

---

## ğŸ“š å­¦ä¹ æ£€æŸ¥æ¸…å•

å®Œæˆå­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿ:

- [ ] **è§£é‡Š Ï€â‚€.â‚… çš„æ ¸å¿ƒåˆ›æ–°**: AdaRMS æœºåˆ¶
- [ ] **å¯¹æ¯” Ï€â‚€ å’Œ Ï€â‚€.â‚…**: 5å¤§æ ¸å¿ƒå·®å¼‚
- [ ] **ç”»å‡ºå®Œæ•´æ¶æ„å›¾**: Prefix + Suffix + åŒæ¨¡å‹
- [ ] **ç†è§£ AdaRMS å·¥ä½œåŸç†**: æ¡ä»¶å½’ä¸€åŒ–çš„æ•°å­¦å’Œä»£ç 
- [ ] **æè¿°æ¨ç†æµç¨‹**: ODE æ±‚è§£ + AdaRMS æ³¨å…¥
- [ ] **æè¿°è®­ç»ƒæµç¨‹**: Flow Matching + é€Ÿåº¦åœºé¢„æµ‹
- [ ] **ç†è§£æ³¨æ„åŠ› mask**: Prefix-LM çš„æ„å»ºæ–¹å¼
- [ ] **å¯¹æ¯”å››å¤§æ¨¡å‹**: ACT, DP, Ï€â‚€, Ï€â‚€.â‚… çš„ä¼˜åŠ£
- [ ] **å›ç­”é¢è¯•é—®é¢˜**: 10+ å¸¸è§é—®é¢˜

---

## ğŸ”— å‚è€ƒèµ„æ–™

### è®ºæ–‡
- **Ï€â‚€.â‚… (2025)**: [Ï€â‚€.â‚…: a Vision-Language-Action Model with Open-World Generalization](https://arxiv.org/abs/2504.16054)
- **Ï€â‚€ (2024)**: [Ï€â‚€: A Vision-Language-Action Flow Model for General Robot Control](https://arxiv.org/abs/2410.24164)
- **Flow Matching (2022)**: [Flow Matching for Generative Modeling](https://arxiv.org/abs/2210.02747)
- **AdaIN (2017)**: [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization](https://arxiv.org/abs/1703.06868)

### ä»£ç 
- **æœ¬ä»“åº“**: [src/lerobot/policies/pi05/](src/lerobot/policies/pi05/)
- **å®˜æ–¹å®ç°**: [OpenPI](https://github.com/Physical-Intelligence/openpi)
- **PaliGemma**: [google/paligemma](https://huggingface.co/google/paligemma)

### åšå®¢
- **Ï€â‚€.â‚… å®˜æ–¹åšå®¢**: [Physical Intelligence Blog](https://www.physicalintelligence.company/blog/pi05)
- **Flow Matching æ•™ç¨‹**: [Flow Matching Guide](https://mlg.eng.cam.ac.uk/blog/2024/01/20/flow-matching.html)

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **å¯¹æ¯”å­¦ä¹ **
   - å…ˆå›é¡¾ Diffusion Policy (æ‰©æ•£æ¨¡å‹åŸºç¡€)
   - å¯¹æ¯” Ï€â‚€ å’Œ Ï€â‚€.â‚… çš„ä»£ç å·®å¼‚
   - ç†è§£ AdaRMS vs FiLM vs Concat çš„åŒºåˆ«

2. **åŠ¨æ‰‹å®éªŒ**
   - å¯è§†åŒ– AdaRMS çš„ scale/shift éšæ—¶é—´å˜åŒ–
   - å¯¹æ¯”ä¸åŒæ—¶é—´é‡‡æ ·ç­–ç•¥çš„æ•ˆæœ
   - å°è¯•ä¿®æ”¹ `use_adarms=[False, True]` çœ‹æ•ˆæœ

3. **ä»£ç è¿½è¸ª**
   - ä» `forward()` å…¥å£è·Ÿè¸ªæ•´ä¸ªæµç¨‹
   - åœ¨ AdaRMS å±‚æ‰“æ–­ç‚¹è§‚å¯Ÿæ¡ä»¶æ³¨å…¥
   - å¯¹æ¯” `embed_suffix` åœ¨ Ï€â‚€ å’Œ Ï€â‚€.â‚… çš„å®ç°

4. **ç”»å›¾æ€»ç»“**
   - ç”»å‡º AdaRMS çš„æ•°æ®æµå›¾
   - ç”»å‡ºæ³¨æ„åŠ› mask çš„çŸ©é˜µ
   - ç”»å‡ºåŒæ¨¡å‹çš„äº¤äº’æ–¹å¼

---

**ç¥å­¦ä¹ é¡ºåˆ©ï¼Ï€â‚€.â‚… æ˜¯ç›®å‰æœ€å…ˆè¿›çš„ VLA æ¨¡å‹ï¼ŒæŒæ¡å®ƒå°†å¸®åŠ©ä½ ç†è§£æœºå™¨äººå­¦ä¹ çš„æœ€æ–°è¿›å±• ğŸš€**

---

## ğŸ”¬ æ·±å…¥ç†è§£ï¼šState å¤„ç†ä¸ Pretraining

### ğŸ¤” é—®é¢˜ 1: Ï€â‚€.â‚… æ˜¯å¦ä½¿ç”¨ Stateï¼Ÿ

**ç­”æ¡ˆï¼šâŒ Ï€â‚€.â‚… å®Œå…¨ä¸ä½¿ç”¨ Stateï¼**

#### å¯¹æ¯”åˆ†æ

| ç‰¹æ€§ | Ï€â‚€ | Ï€â‚€.â‚… |
|------|-----|------|
| **Config ä¸­å®šä¹‰ state** | âœ… æœ‰ `max_state_dim` | âœ… æœ‰ï¼ˆä½†ä¸ç”¨ï¼‰ |
| **æ¨¡å‹ä¸­ä½¿ç”¨ state** | âœ… ä½œä¸ºç‹¬ç«‹ token | âŒ å®Œå…¨ä¸ç”¨ |
| **state_proj å±‚** | âœ… æœ‰ | âŒ æ—  |
| **State ä½ç½®** | Suffix ç¬¬ä¸€ä¸ª token | N/A |
| **State â†’ Language** | âŒ å¦ï¼Œä½œä¸ºç‹¬ç«‹ token | âŒ å¦ï¼Œç›´æ¥ä¸ç”¨ |
| **ä¾èµ–çš„è§‚å¯Ÿ** | å›¾åƒ + è¯­è¨€ + State | ä»…å›¾åƒ + è¯­è¨€ |

#### Ï€â‚€ çš„ State ä½¿ç”¨

```python
# modeling_pi0.py:525
self.state_proj = nn.Linear(max_state_dim, width)  # ä¸“é—¨çš„æŠ•å½±å±‚

# modeling_pi0.py:637-657
def embed_suffix(self, state, noisy_actions, timestep):
    # Step 1: æŠ•å½± state
    state_emb = self.state_proj(state)  # [B, 32] -> [B, 1024]
    embs.append(state_emb[:, None, :])  # ä½œä¸ºç¬¬ä¸€ä¸ª token

    # Step 2: æŠ•å½± action
    action_emb = self.action_in_proj(noisy_actions)

    # Step 3: æ—¶é—´æ‹¼æ¥åˆ° action
    time_emb_expanded = time_emb[:, None, :].expand(-1, 50, -1)
    action_time = torch.cat([action_emb, time_emb_expanded], dim=-1)

    # å®Œæ•´ suffix: [state, action_0, action_1, ..., action_49]
    return torch.cat([state_emb, action_time_emb], dim=1)

# modeling_pi0.py:1160
state = self.prepare_state(batch)  # ä» batch ä¸­æå– state
```

**Ï€â‚€ çš„ Suffix ç»“æ„ï¼š**
```
Suffix = [
    state_token,      # 1 ä¸ª token [B, 1, 1024]
    action_token_0,   # ç¬¬ 1 æ­¥åŠ¨ä½œ
    action_token_1,   # ç¬¬ 2 æ­¥åŠ¨ä½œ
    ...
    action_token_49,  # ç¬¬ 50 æ­¥åŠ¨ä½œ
]
å½¢çŠ¶: [B, 51, 1024]  (1 ä¸ª state + 50 ä¸ª action)
```

#### Ï€â‚€.â‚… ä¸ä½¿ç”¨ State

```python
# modeling_pi05.py: æ²¡æœ‰ state_proj å±‚ï¼

# modeling_pi05.py:659-719
def embed_suffix(self, noisy_actions, timestep):
    # âŒ æ²¡æœ‰ state å‚æ•°ï¼
    # âœ… åªå¤„ç† action å’Œ timestep

    # Step 1: æŠ•å½± action
    action_emb = self.action_in_proj(noisy_actions)  # [B, 50, 1024]

    # Step 2: æ—¶é—´ä½œä¸º AdaRMS æ¡ä»¶ï¼ˆä¸æ‹¼æ¥ï¼‰
    time_emb = create_sinusoidal_pos_embedding(timestep, ...)
    adarms_cond = time_mlp(time_emb)  # [B, 1024]

    # å®Œæ•´ suffix: åªæœ‰ action
    return action_emb, adarms_cond  # [B, 50, 1024], [B, 1024]

# modeling_pi05.py:722
def forward(self, images, img_masks, tokens, masks, actions, ...):
    # âŒ æ²¡æœ‰ state å‚æ•°ï¼
```

**Ï€â‚€.â‚… çš„ Suffix ç»“æ„ï¼š**
```
Suffix = [
    action_token_0,   # ç¬¬ 1 æ­¥åŠ¨ä½œ
    action_token_1,   # ç¬¬ 2 æ­¥åŠ¨ä½œ
    ...
    action_token_49,  # ç¬¬ 50 æ­¥åŠ¨ä½œ
]
å½¢çŠ¶: [B, 50, 1024]  (åªæœ‰ 50 ä¸ª action tokens)
```

#### ä¸ºä»€ä¹ˆ Config ä¸­è¿˜æœ‰ State å®šä¹‰ï¼Ÿ

```python
# configuration_pi05.py:114-119
if "observation.state" not in self.input_features:
    state_feature = PolicyFeature(
        type=FeatureType.STATE,
        shape=(self.max_state_dim,),
    )
    self.input_features["observation.state"] = state_feature
```

**å¯èƒ½çš„åŸå› ï¼š**
1. **æ¡†æ¶å…¼å®¹æ€§**: LeRobot æ¡†æ¶è¦æ±‚æ‰€æœ‰ç­–ç•¥éƒ½å®šä¹‰ state feature
2. **å‘åå…¼å®¹**: ä¿æŒé…ç½®æ¥å£ä¸€è‡´
3. **æœªæ¥æ‰©å±•**: å¯èƒ½åç»­ç‰ˆæœ¬ä¼šé‡æ–°å¼•å…¥ state

ä½†åœ¨å®é™…è¿è¡Œä¸­ï¼Œ**Ï€â‚€.â‚… å®Œå…¨å¿½ç•¥äº† state ä¿¡æ¯**ï¼Œåªä¾èµ–è§†è§‰å’Œè¯­è¨€ï¼

---

### ğŸ¯ é—®é¢˜ 2: Ï€â‚€.â‚… çš„ä¸¤é˜¶æ®µè®­ç»ƒ

#### è®­ç»ƒé˜¶æ®µåˆ’åˆ†

Ï€â‚€.â‚… çš„å®Œæ•´è®­ç»ƒåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

##### **é˜¶æ®µ 1: Pretrainingï¼ˆé¢„è®­ç»ƒï¼‰**

**è®­ç»ƒå†…å®¹ï¼š**
- **åªè®­ç»ƒ PaliGemma VLM**ï¼ˆè§†è§‰-è¯­è¨€æ¨¡å‹ï¼‰
- **ä¸è®­ç»ƒ Action Expert**

**ä½¿ç”¨çš„æ•°æ®ï¼š**
1. å¤šæ¨¡æ€ç½‘ç»œæ•°æ®
   - å›¾åƒæè¿°ï¼ˆImage Captioningï¼‰
   - è§†è§‰é—®ç­”ï¼ˆVQAï¼‰
   - ç›®æ ‡æ£€æµ‹ï¼ˆObject Detectionï¼‰
2. **ç¦»æ•£åŠ¨ä½œ tokens**ï¼ˆæ¥è‡ª FASTï¼‰â­
3. è·¨ embodiment æœºå™¨äººæ•°æ®
4. è¯­è¨€æŒ‡ä»¤æ•°æ®

**è®­ç»ƒä»»åŠ¡ï¼š**
1. **ä¼ ç»Ÿ VLM ä»»åŠ¡**
   ```python
   # ç¤ºä¾‹ï¼šå›¾åƒæè¿°
   è¾“å…¥: [image_tokens, prompt_tokens]
   ç›®æ ‡: é¢„æµ‹æè¿°æ–‡æœ¬çš„ä¸‹ä¸€ä¸ª token
   æŸå¤±: CrossEntropyLoss(logits, next_token)
   ```

2. **Predict Next Action Token**ï¼ˆÏ€â‚€.â‚… çš„åˆ›æ–°ï¼‰â­
   ```python
   # ä½¿ç”¨ FAST å°†è¿ç»­åŠ¨ä½œç¦»æ•£åŒ–
   actions_continuous = [0.1, 0.2, ...]  # [B, 50, 7]
   action_tokens = FAST_tokenizer.encode(actions_continuous)  # [B, 50]
   # ä¾‹å¦‚: [45231, 12043, 98234, ...]

   # è¾“å…¥åºåˆ—
   input_sequence = [
       image_tokens,        # 196 ä¸ª
       language_tokens,     # N ä¸ª
       action_tokens[:-1]   # 49 ä¸ªï¼ˆä¸åŒ…æ‹¬æœ€åä¸€ä¸ªï¼‰
   ]

   # VLM forward
   outputs = paligemma.language_model.forward(
       inputs_embeds=embed(input_sequence)
   )
   logits = paligemma.language_model.lm_head(outputs.last_hidden_state)
   # logits shape: [B, seq_len, 257152] (è¯è¡¨å¤§å°)

   # Next Token Prediction Loss
   action_logits = logits[:, -(chunk_size-1):, :]  # å–åŠ¨ä½œéƒ¨åˆ†
   target_tokens = action_tokens[:, 1:]  # ç›®æ ‡æ˜¯ä¸‹ä¸€ä¸ª token
   loss = CrossEntropyLoss(action_logits, target_tokens)
   ```

**å…³é”®ç‚¹ï¼š**
- VLM çš„ `lm_head` (Linear: 2048 â†’ 257152) è¢«ç”¨æ¥é¢„æµ‹åŠ¨ä½œ tokens
- åŠ¨ä½œè¢«å½“ä½œ"ç‰¹æ®Šçš„è¯­è¨€"æ¥å­¦ä¹ 
- è®© VLM ç†è§£åŠ¨ä½œåºåˆ—çš„è¯­ä¹‰æ¨¡å¼

**ä¸ Ï€â‚€ çš„åŒºåˆ«ï¼š**
- Ï€â‚€: VLM ä» PaliGemma åˆå§‹åŒ–ï¼Œå‚æ•°ä¸æ›´æ–°ï¼ˆåªæ˜¯ç‰¹å¾æå–å™¨ï¼‰
- Ï€â‚€.â‚…: VLM å‚æ•°**å‚ä¸æ›´æ–°**ï¼Œå­¦ä¹ é¢„æµ‹åŠ¨ä½œ tokens

##### **é˜¶æ®µ 2: Post-training/Fine-tuningï¼ˆåè®­ç»ƒï¼‰**

**è®­ç»ƒå†…å®¹ï¼š**
- **å†»ç»“ PaliGemma VLM**ï¼ˆå‚æ•°ä¸æ›´æ–°ï¼‰
- **åªè®­ç»ƒ Action Expert** å’Œç›¸å…³æŠ•å½±å±‚

**ä½¿ç”¨çš„æ•°æ®ï¼š**
- é«˜è´¨é‡çš„æœºå™¨äººæ“ä½œæ¼”ç¤ºæ•°æ®
- ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ï¼ˆå¦‚ Liberoï¼‰

**è®­ç»ƒæ–¹æ³•ï¼š**
```python
# ===== ä¸å†ä½¿ç”¨ç¦»æ•£ tokensï¼ =====
# ===== æ”¹ç”¨è¿ç»­åŠ¨ä½œç©ºé—´ + Flow Matching =====

# Step 1: é‡‡æ ·å™ªå£°å’Œæ—¶é—´
noise = torch.randn(B, 50, 7)  # è¿ç»­å™ªå£°
time = sample_beta(1.5, 1.0, B)  # [0.001, 1.0]

# Step 2: Flow Matching å‰å‘è¿‡ç¨‹
x_t = time * noise + (1 - time) * actions  # çº¿æ€§æ’å€¼
target_velocity = noise - actions

# Step 3: é¢„æµ‹é€Ÿåº¦åœºï¼ˆä¸ç”¨ lm_headï¼‰
suffix_embs, adarms_cond = embed_suffix(x_t, time)
suffix_hidden = action_expert.forward(
    suffix_embs,
    adarms_cond=adarms_cond  # æ—¶é—´æ¡ä»¶
)

# Step 4: è¾“å‡ºè¿ç»­åŠ¨ä½œï¼ˆä¸æ˜¯ tokensï¼‰
predicted_velocity = action_out_proj(suffix_hidden)  # [B, 50, 7]

# Step 5: Flow Matching Loss
loss = MSELoss(predicted_velocity, target_velocity)
```

**å…³é”®ç‚¹ï¼š**
- **lm_head è¢«ä¸¢å¼ƒ**ï¼Œä¸å†ä½¿ç”¨
- æ”¹ç”¨ `action_out_proj` (Linear: 1024 â†’ 7) è¾“å‡ºè¿ç»­åŠ¨ä½œ
- VLM åªæä¾›è¯­ä¹‰ç‰¹å¾ï¼Œä¸å‚ä¸åŠ¨ä½œé¢„æµ‹

**ç›®æ ‡ï¼š**
- å°†é€šç”¨çš„è§†è§‰-è¯­è¨€ç†è§£è½¬åŒ–ä¸ºç²¾ç¡®çš„æœºå™¨äººæ§åˆ¶
- å­¦ä¹ ç‰¹å®šä»»åŠ¡çš„æ“ä½œç­–ç•¥

#### ä»£ç ä¸­çš„ä½“ç°

##### **Pretraining é˜¶æ®µï¼ˆæœªåœ¨ LeRobot å®ç°ï¼‰**

```python
# ===== Physical Intelligence çš„å†…éƒ¨å®ç°ï¼ˆæœªå¼€æºï¼‰=====

class PI05Pretraining(nn.Module):
    def __init__(self):
        # å®Œæ•´çš„ PaliGemmaï¼ˆåŒ…æ‹¬ lm_headï¼‰
        self.paligemma = PaliGemmaForConditionalGeneration(...)
        # lm_head: Linear(2048, 257152) â† ç”¨äºé¢„æµ‹ tokens

        # FAST tokenizerï¼ˆåŠ¨ä½œç¦»æ•£åŒ–ï¼‰
        self.fast_tokenizer = FAST_Tokenizer(...)

    def forward(self, images, language, actions):
        # 1. ç¦»æ•£åŒ–åŠ¨ä½œ
        action_tokens = self.fast_tokenizer.encode(actions)

        # 2. æ„å»ºè¾“å…¥åºåˆ—
        input_ids = torch.cat([
            image_token_ids,
            language_token_ids,
            action_tokens[:-1]  # ä¸åŒ…æ‹¬æœ€åä¸€ä¸ª
        ], dim=1)

        # 3. VLM forwardï¼ˆä½¿ç”¨ lm_headï¼‰
        outputs = self.paligemma(input_ids=input_ids)
        logits = outputs.logits  # [B, seq_len, 257152]

        # 4. è®¡ç®— next token prediction loss
        shift_logits = logits[:, :-1, :].contiguous()
        shift_labels = input_ids[:, 1:].contiguous()
        loss = CrossEntropyLoss(shift_logits, shift_labels)

        return loss
```

##### **Post-training é˜¶æ®µï¼ˆLeRobot å®ç°çš„éƒ¨åˆ†ï¼‰**

```python
# ===== modeling_pi05.py:722-779 =====

class PI05Pytorch(nn.Module):
    def __init__(self):
        # PaliGemmaï¼ˆåŒ…å« lm_headï¼Œä½†ä¸ä½¿ç”¨ï¼‰
        self.paligemma_with_expert = PaliGemmaWithExpertModel(...)
        # paligemma.language_model.lm_head: Linear(2048, 257152) â† å­˜åœ¨ä½†ä¸ç”¨

        # Action Expert
        self.gemma_expert = GemmaForCausalLM(...)

        # æŠ•å½±å±‚ï¼ˆç”¨äºè¿ç»­åŠ¨ä½œï¼‰
        self.action_in_proj = nn.Linear(7, 1024)
        self.action_out_proj = nn.Linear(1024, 7)  # â† å®é™…ä½¿ç”¨è¿™ä¸ª

    def forward(self, images, tokens, masks, actions, time):
        # 1. è¿ç»­åŠ¨ä½œï¼ˆä¸ç¦»æ•£åŒ–ï¼‰
        x_t = time * noise + (1 - time) * actions

        # 2. Embed suffixï¼ˆä¸ç”¨ FAST tokensï¼‰
        suffix_embs, adarms_cond = self.embed_suffix(x_t, time)

        # 3. åŒæ¨¡å‹ forwardï¼ˆä¸ç”¨ lm_headï¼‰
        suffix_hidden = self.paligemma_with_expert.forward(
            prefix_embs,
            suffix_embs,
            adarms_cond=[None, adarms_cond]
        )

        # 4. è¾“å‡ºè¿ç»­åŠ¨ä½œï¼ˆä¸æ˜¯ tokensï¼‰
        predicted_velocity = self.action_out_proj(suffix_hidden)

        # 5. Flow Matching Loss
        loss = MSELoss(predicted_velocity, noise - actions)

        return loss
```

#### lm_head çš„"åŒé‡èº«ä»½"

**PaliGemma çš„ç»“æ„ï¼š**
```python
PaliGemmaForConditionalGeneration(
    vision_tower: SiglipVisionModel,
    multi_modal_projector: PaliGemmaMultiModalProjector,
    language_model: GemmaForCausalLM(
        model: GemmaModel,
        lm_head: Linear(2048, 257152)  # â† è¿™é‡Œï¼
    )
)
```

**ä¸¤ç§å·¥ä½œæ¨¡å¼ï¼š**

1. **Pretraining æ¨¡å¼**ï¼ˆPhysical Intelligence å†…éƒ¨ï¼‰ï¼š
   ```python
   # ä½¿ç”¨ lm_head é¢„æµ‹ç¦»æ•£ tokens
   hidden_states = vlm.forward(image_tokens + lang_tokens + action_tokens)
   next_token_logits = vlm.lm_head(hidden_states)  # [B, seq, 257152]
   loss = CrossEntropyLoss(next_token_logits, target_tokens)
   ```

2. **Post-training æ¨¡å¼**ï¼ˆLeRobot å®ç°ï¼‰ï¼š
   ```python
   # lm_head å­˜åœ¨ä½†ä¸ä½¿ç”¨ï¼
   hidden_states = vlm.forward(image_emb + lang_emb)
   # vlm.lm_head è¢«å¿½ç•¥

   # æ”¹ç”¨ action_out_proj
   action_features = expert.forward(action_emb, past_kv=hidden_states)
   actions = action_out_proj(action_features)  # [B, 50, 7] è¿ç»­
   loss = FlowMatchingLoss(actions, targets)
   ```

---

### ğŸ” é—®é¢˜ 3: VLM å¦‚ä½•å‚ä¸åŠ¨ä½œé¢„æµ‹ï¼Ÿ

#### å…³é”®è¯¯è§£æ¾„æ¸…

**âŒ é”™è¯¯ç†è§£ï¼š** VLM ç›´æ¥è¾“å‡ºåŠ¨ä½œ tokens
**âœ… æ­£ç¡®ç†è§£ï¼š** VLM é€šè¿‡ cross-attention æä¾›è¯­ä¹‰ç†è§£ç»™ Expert

#### å®Œæ•´æ•°æ®æµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è®­ç»ƒæ—¶çš„å®Œæ•´æµç¨‹                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¾“å…¥:
â”œâ”€ images: [B, 3, 224, 224]
â”œâ”€ language: "pick up the red cup"
â””â”€ actions: [B, 50, 7] (çœŸå®åŠ¨ä½œ)

Step 1: å‡†å¤‡è¾“å…¥
â”œâ”€ noise = randn([B, 50, 7])
â”œâ”€ time = Beta(1.5, 1.0) â†’ [B]
â””â”€ x_t = time * noise + (1-time) * actions  # Flow Matching

Step 2: Embed Prefix
â”œâ”€ image_emb = SigLIP(images)  # [B, 196, 2048]
â”œâ”€ lang_emb = Gemma_embed(tokens)  # [B, N, 2048]
â””â”€ prefix_embs = concat([image_emb, lang_emb])  # [B, 196+N, 2048]

Step 3: Embed Suffix â­
â”œâ”€ action_emb = action_in_proj(x_t)  # [B, 50, 7] â†’ [B, 50, 1024]
â”‚   # æ³¨æ„ï¼šè¾“å…¥çš„æ˜¯å™ªå£°æ··åˆçš„åŠ¨ä½œï¼Œä¸æ˜¯ tokensï¼
â”‚
â””â”€ time_emb = sinusoidal_embed(time)  # [B, 1024]
    adarms_cond = time_mlp(time_emb)  # [B, 1024]
    # æ—¶é—´ä¸ä½œä¸º tokenï¼Œè€Œæ˜¯ AdaRMS æ¡ä»¶

Step 4: åŒæ¨¡å‹è”åˆå¤„ç†
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PaliGemma å¤„ç† prefix                        â”‚
â”‚  â”œâ”€ Layer 1-18                               â”‚
â”‚  â”‚  â”œâ”€ Self-Attention (åŒå‘ï¼Œprefixå†…)      â”‚
â”‚  â”‚  â”œâ”€ Cross-Attention (çœ‹ prefix)          â”‚
â”‚  â”‚  â””â”€ MLP                                  â”‚
â”‚  â””â”€ è¾“å‡º: prefix_hidden [B, 196+N, 2048]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼  (QKV concat)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Action Expert å¤„ç† suffix â­                 â”‚
â”‚  â”œâ”€ Layer 1-18                               â”‚
â”‚  â”‚  â”œâ”€ AdaRMS(cond=adarms_cond) â­           â”‚
â”‚  â”‚  â”œâ”€ Self-Attention (å› æœï¼Œsuffixå†…)      â”‚
â”‚  â”‚  â”œâ”€ Cross-Attention (å¯ä»¥çœ‹ prefix!)     â”‚
â”‚  â”‚  â”‚   â””â”€ Q: suffix, K/V: prefix + suffix â”‚
â”‚  â”‚  â””â”€ MLP                                  â”‚
â”‚  â””â”€ è¾“å‡º: suffix_hidden [B, 50, 1024]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
Step 5: è¾“å‡ºè¿ç»­åŠ¨ä½œ
â””â”€ predicted_v = action_out_proj(suffix_hidden)  # [B, 50, 7]
   loss = MSE(predicted_v, noise - actions)
```

#### å…³é”®æœºåˆ¶ï¼šCross-Attention

```python
# compute_layer_complete() ä¸­çš„å…³é”®ä»£ç 
# modeling_pi05.py:252-256

# Step 1: åˆ†åˆ«è®¡ç®— QKV
prefix_queries = paligemma.q_proj(prefix_hidden)  # [B, 196+N, 2048]
suffix_queries = expert.q_proj(suffix_hidden)     # [B, 50, 1024]

prefix_keys = paligemma.k_proj(prefix_hidden)
suffix_keys = expert.k_proj(suffix_hidden)

prefix_values = paligemma.v_proj(prefix_hidden)
suffix_values = expert.v_proj(suffix_hidden)

# Step 2: Concatï¼ˆå®ç° cross-attentionï¼‰â­
queries = torch.cat([prefix_queries, suffix_queries], dim=1)
keys = torch.cat([prefix_keys, suffix_keys], dim=1)
values = torch.cat([prefix_values, suffix_values], dim=1)

# Step 3: æ³¨æ„åŠ›è®¡ç®—
attention_scores = (queries @ keys.transpose(-2, -1)) / sqrt(d_k)
# å½¢çŠ¶: [B, (196+N+50), (196+N+50)]

# åº”ç”¨ attention maskï¼ˆæ§åˆ¶è°èƒ½çœ‹åˆ°è°ï¼‰
attention_scores = attention_scores.masked_fill(~attention_mask, -inf)

attention_weights = softmax(attention_scores, dim=-1)
output = attention_weights @ values
```

**æ³¨æ„åŠ›çŸ©é˜µå¯è§†åŒ–ï¼š**
```
         Prefix (196+N)     Suffix (50)
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Prefix  â”‚   åŒå‘ Attention  â”‚   âŒ çœ‹ä¸åˆ°  â”‚
(196+N) â”‚   (å½¼æ­¤å¯è§)      â”‚  (å•å‘é™åˆ¶) â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Suffix  â”‚  âœ… å¯ä»¥çœ‹åˆ°       â”‚  å› æœ Attn  â”‚
(50)    â”‚  (Cross-Attn!)   â”‚  (åªçœ‹è¿‡å») â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**VLM çš„è¯­ä¹‰å¦‚ä½•ä¼ é€’ç»™ Expertï¼Ÿ**

1. **é€šè¿‡ Cross-Attention çš„ Key-Value**
   ```python
   # Suffix çš„ Query å¯ä»¥ attend åˆ° Prefix çš„ Key-Value
   suffix_query @ prefix_key â†’ attention_weight
   attention_weight @ prefix_value â†’ è¯­ä¹‰ä¿¡æ¯ä¼ é€’
   ```

2. **è¯­ä¹‰ä¼ é€’ç¤ºä¾‹**
   ```
   è¯­è¨€æŒ‡ä»¤: "pick up the red cup"
   VLM ç†è§£: [red, cup, pick, spatial_relation, ...]
                     â†“ (é€šè¿‡ Cross-Attention)
   Expert è·å–: "æˆ‘éœ€è¦ç”Ÿæˆ'æ‹¿èµ·'çš„åŠ¨ä½œåºåˆ—"
                "ç›®æ ‡æ˜¯'çº¢è‰²çš„æ¯å­'"
                     â†“
   ç”ŸæˆåŠ¨ä½œ: [approach, grasp, lift, ...]
   ```

#### å®Œæ•´è¾“å…¥ç»“æ„æ€»ç»“

**ç»™ Action Expert çš„è¾“å…¥ token é•¿ä»€ä¹ˆæ ·ï¼Ÿ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å®Œæ•´è¾“å…¥åºåˆ—ï¼ˆè®­ç»ƒæ—¶ï¼‰                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Prefix             â”‚           Suffix              â”‚
â”‚   (VLM å¤„ç†)            â”‚      (Expert å¤„ç†)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Image Embeddings        â”‚ Action Embeddings             â”‚
â”‚   - Token 0-195 (196ä¸ª) â”‚   - Token 0-49 (50ä¸ª)        â”‚
â”‚   - [B, 196, 2048]      â”‚   - [B, 50, 1024]            â”‚
â”‚   - æ¥è‡ª SigLIP         â”‚   - æ¥è‡ª action_in_proj       â”‚
â”‚                         â”‚                               â”‚
â”‚ Language Embeddings     â”‚ å…³é”®ç‚¹ï¼š                      â”‚
â”‚   - Token 196-N         â”‚ âŒ ä¸åŒ…å«é¢„æµ‹çš„åŠ¨ä½œ token     â”‚
â”‚   - [B, seq_len, 2048]  â”‚ âŒ ä¸åŒ…å«ç¦»æ•£ token           â”‚
â”‚   - æ¥è‡ª Gemma embed    â”‚ âœ… åŒ…å«å™ªå£°æ··åˆçš„è¿ç»­åŠ¨ä½œ     â”‚
â”‚                         â”‚ âœ… æ—¶é—´ä¿¡æ¯åœ¨ AdaRMS æ¡ä»¶ä¸­   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Suffix çš„è¯¦ç»†ç»“æ„ï¼š**

```python
# è®­ç»ƒæ—¶
noisy_actions = 0.3 * noise + 0.7 * actions  # [B, 50, 7]
# ä¾‹å¦‚: [[0.2, 0.5, ...], [0.3, 0.4, ...], ...]

action_emb = action_in_proj(noisy_actions)  # [B, 50, 1024]
# ä¾‹å¦‚: [[e_0], [e_1], ..., [e_49]]
# æ¯ä¸ª e_i æ˜¯ 1024 ç»´çš„è¿ç»­åµŒå…¥

# æ¨ç†æ—¶ï¼ˆè¿­ä»£å»å™ªï¼‰
x_t = torch.randn(B, 50, 7)  # åˆå§‹çº¯å™ªå£°
for step in range(10):
    action_emb = action_in_proj(x_t)  # [B, 50, 1024]
    v_t = model.forward(action_emb, ...)
    x_t = x_t + v_t * dt  # é€æ­¥å˜æˆå¹²å‡€åŠ¨ä½œ
```

---

### ğŸ“Š è®ºæ–‡ vs ä»£ç å¯¹åº”å…³ç³»

| è®ºæ–‡æè¿° | ä»£ç ä½ç½® | å®ç°çŠ¶æ€ | è¯´æ˜ |
|----------|----------|----------|------|
| **Pretraining with FAST tokens** | âŒ æœªå®ç° | Physical Intelligence å†…éƒ¨ | ä½¿ç”¨ lm_head é¢„æµ‹ç¦»æ•£ tokens |
| **Predict next action token** | âŒ æœªå®ç° | éœ€è¦ lm_head + FAST | Pretraining çš„æ ¸å¿ƒåˆ›æ–° |
| **Post-training with Flow Matching** | âœ… å·²å®ç° | [modeling_pi05.py:722-779](src/lerobot/policies/pi05/modeling_pi05.py#L722-L779) | LeRobot å®ç°çš„éƒ¨åˆ† |
| **Action Expert** | âœ… å·²å®ç° | [modeling_pi05.py:393](src/lerobot/policies/pi05/modeling_pi05.py#L393) | Gemma 300M |
| **AdaRMS conditioning** | âœ… å·²å®ç° | [modeling_pi05.py:692](src/lerobot/policies/pi05/modeling_pi05.py#L692) | æ—¶é—´æ¡ä»¶æ³¨å…¥ |
| **Cross-attention (VLMâ†”Expert)** | âœ… å·²å®ç° | [modeling_pi05.py:252-256](src/lerobot/policies/pi05/modeling_pi05.py#L252-L256) | QKV concat å®ç° |
| **lm_head for action tokens** | âš ï¸ å­˜åœ¨ä½†ä¸ç”¨ | åœ¨ PaliGemma ä¸­ä½†è¢«å¿½ç•¥ | Pretraining ç”¨ï¼ŒPost-training ä¸ç”¨ |

---

### ğŸ“ æ ¸å¿ƒè¦ç‚¹æ€»ç»“

1. **Ï€â‚€.â‚… ä¸ä½¿ç”¨ State**
   - Config ä¸­æœ‰å®šä¹‰ï¼ˆæ¡†æ¶å…¼å®¹æ€§ï¼‰
   - æ¨¡å‹ä¸­å®Œå…¨ä¸ä½¿ç”¨
   - ä¾é è§†è§‰è§‚å¯Ÿéšå¼æ¨æ–­çŠ¶æ€

2. **ä¸¤é˜¶æ®µè®­ç»ƒçš„æœ¬è´¨**
   - **Pretraining**: VLM å­¦ä¹ é¢„æµ‹åŠ¨ä½œ tokensï¼ˆç±»ä¼¼è¯­è¨€å»ºæ¨¡ï¼‰
   - **Post-training**: Expert å­¦ä¹ è¿ç»­åŠ¨ä½œç©ºé—´ï¼ˆFlow Matchingï¼‰
   - ä¸¤ä¸ªé˜¶æ®µä½¿ç”¨**å®Œå…¨ä¸åŒçš„è®­ç»ƒç›®æ ‡å’ŒæŸå¤±å‡½æ•°**

3. **VLM çš„è§’è‰²**
   - âŒ ä¸ç›´æ¥è¾“å‡ºåŠ¨ä½œ tokens
   - âœ… é€šè¿‡ Cross-Attention æä¾›è¯­ä¹‰ç†è§£
   - âœ… å¸®åŠ© Expert ç†è§£"æ‹¿èµ·æ¯å­"çš„æ„å›¾

4. **Expert çš„è¾“å…¥**
   - âŒ ä¸æ˜¯ç¦»æ•£çš„é¢„æµ‹ tokens
   - âœ… æ˜¯è¿ç»­çš„å™ªå£°æ··åˆåŠ¨ä½œåµŒå…¥
   - âœ… é€šè¿‡ Cross-Attention è·å– VLM çš„è¯­ä¹‰ä¿¡æ¯

5. **lm_head çš„"é—å¼ƒ"**
   - Pretraining æ—¶ä½¿ç”¨ï¼ˆé¢„æµ‹ tokensï¼‰
   - Post-training æ—¶ä¸ä½¿ç”¨ï¼ˆæ”¹ç”¨ action_out_projï¼‰
   - ä»£ç ä¸­å­˜åœ¨ä½†ä»æœªè°ƒç”¨

---

è¿™æ ·çš„è®¾è®¡è®© Ï€â‚€.â‚… èƒ½å¤Ÿï¼š
- âœ… åœ¨ Pretraining é˜¶æ®µåˆ©ç”¨ç¦»æ•£ tokens å­¦ä¹ é€šç”¨è¯­ä¹‰
- âœ… åœ¨ Post-training é˜¶æ®µåˆ‡æ¢åˆ°è¿ç»­ç©ºé—´è¿›è¡Œç²¾ç¡®æ§åˆ¶
- âœ… é€šè¿‡ Cross-Attention å®ç° VLM å’Œ Expert çš„æœ‰æ•ˆåä½œ
